{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58ce506",
   "metadata": {},
   "source": [
    "# Star Wars Galaxy Explorers (Phase 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3fdf11",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    text-align: center;\n",
    "    font-family: Arial, sans-serif;\n",
    "    color: yellow;\n",
    "    background: black;\n",
    "    padding: 20px;\n",
    "\">\n",
    "    <p style=\"font-size: 16px; margin: 10px 0;\">Oh no! A war broke out!</p>\n",
    "    <p style=\"font-size: 20px; margin: 10px 0;\">To help the drones, they are given limited 'vision'</p>\n",
    "    <p style=\"font-size: 24px; margin: 10px 0;\">to avoid the hostile ships engaged in battle</p>\n",
    "    <p style=\"font-size: 28px; margin: 10px 0;\">with one another all over the Outer Rim,</p>\n",
    "    <p style=\"font-size: 32px; margin: 10px 0;\">all the while doing their job in planet discovering.</p>\n",
    "    <p style=\"font-size: 36px; margin: 10px 0;\">You need to find planets while avoiding being caught in the conflict.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708d90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gymnasium-related dependencies\n",
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "# Import Stable Baselines3-related dependencies\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "\n",
    "# Import pygame-related dependencies\n",
    "import pygame\n",
    "\n",
    "# Import helper dependencies\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import local classes\n",
    "from entity_manager import EntityManager\n",
    "from npc_ships import SeperatistShip, RepublicShip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6ecd9a",
   "metadata": {},
   "source": [
    "## Build Outer Rim POMDP (Partially Observable Markov Decision Process) RL Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88746eb",
   "metadata": {},
   "source": [
    "### What is the MDP components of the Outer Rim POMDP RL Environment?\n",
    "\n",
    "**1. (Reality) State Space**\n",
    "- all actual states of the Outer Rim POMDP RL Environment\n",
    "\n",
    "| **Component**                       | **Type / Description**                             | **Purpose**                                                                         |\n",
    "| ----------------------------------- | -------------------------------------------------- | ----------------------------------------------------------------------------------- |\n",
    "| `map`                               | 2D grid consisting of different objects, denoted by characters (`' '`, `'#'`, `'.'`, `'S'`), where ' ' is empty space, '#' is a planet, '.' is a visited planet, 'S' is the starting position that the agent can see and remember | Represents environment layout and object locations (empty, planets, visited planets, start positions) |\n",
    "| `state`                             | Tuple `(row, col)`                                 | Current agent location                                                              |\n",
    "| `vision_radius`                     | 2D binary matrix                                   | Tracks all cells the agent has can see at a time, serves as the agent's 'vision'                                            |\n",
    "| `seen_map`                          | 2D binary matrix                                   | Tracks all cells the agent has ever seen, serves as the agent's 'memory'                                            |\n",
    "| `mission_time_before_self_destruct` | Integer countdown                                  | Terminates mission/episode when time runs out                                               |\n",
    "| `planet_reward_map`                 | 2D float matrix                                    | Used to map the dense reward field (halo) from discovered planets                                   |\n",
    "| `discovered_planet`                 | Set of coordinates                                 | Used to track which planets were already visited                                           |\n",
    "| `npc_list`                          | List of enemy/friendly ships with position/state   | Governs danger field and combat logic                                               |\n",
    "| `agent_damage_taken`                | Boolean flag / counter                             | Used to track if agent was damaged by a 'SeparatistShip'                                                        |\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. (Agent's) Observation Space**\n",
    "- all observable states by the agent in the Outer Rim POMDP RL Environment\n",
    "\n",
    "| **Component**                    | **Type / Description**                                 | **Purpose**                                                                         |\n",
    "| -------------------------------- | ------------------------------------------------ | ----------------------------------------------------------------------------------- |\n",
    "| `vision_radius`                     | 2D binary matrix                                   | Tracks all cells the agent has can see at a time, serves as the agent's 'vision'                                            |\n",
    "| `seen_memory` / `reward_memory`                          | 2D binary matrix                                   | Tracks all cells the agent has ever seen, serves as the agent's 'memory' or rewarding areas                                           |\n",
    "| `danger`                         | 2D float matrix (same shape as vision)           | Local perception of enemy threat level                                              |\n",
    "\n",
    "<br>\n",
    "\n",
    "**3. Action Space**\n",
    "- denoted by the type: Discrete(4)\n",
    "\n",
    "| **Index** | **Action Name** | **Meaning**         |\n",
    "| --------- | --------------- | ------------------- |\n",
    "| 0         | Forward         | Forward by 1 pixel  |\n",
    "| 1         | Backward        | Backward by 1 pixel |\n",
    "| 2         | Leftward        | Leftward by 1 pixel |\n",
    "| 3         | Rightward       | Rightward by 1 pixel |\n",
    "\n",
    "<br>\n",
    "\n",
    "**4. Transition Probability**  \n",
    "- Deterministic\n",
    "\n",
    "<br>\n",
    "\n",
    "**5. Reward Function**  \n",
    "- see the 'Calculate Reward with Reward Function' section in the 'step()' function below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4226a2e8",
   "metadata": {},
   "source": [
    "## More about the War\n",
    "This will be a predator-prey situation, with 'SeperatistShip' being the predator and 'RepublicShip' being the prey (idk why lol lets just say the Republic is losing this war and retreating).\n",
    "\n",
    "I did not want to complicate the logic by making health bars or 'SeperatistShip' and 'Republicship' combat stuffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuterRimEnv(Env):\n",
    "    def __init__(self, n_sep, n_rep):\n",
    "        # --- related to world's state spaces --------------------------------------------------------\n",
    "        self.map = self.generate_map()\n",
    "        self.num_rows, self.num_cols = self.map.shape\n",
    "        self.start_position = tuple(np.argwhere(self.map == 'S')[0])\n",
    "        self.state = self.start_position        # Initialising the initial state of the RL Environment\n",
    "        self.n_sep = n_sep                      # number of separatist ships\n",
    "        self.n_rep = n_rep                      # number of republic ships\n",
    "\n",
    "        # --- related to RL agent, observation spaces and action spaces ----------------------------------------------------\n",
    "        self.action_space = Discrete(4)\n",
    "\n",
    "        # Giving the RL agent, 'vision' around it\n",
    "        # Vision radius: e.g. 1 → 3x3 grid (center + 1 square in each direction)\n",
    "        self.vision_radius = 7\n",
    "        obs_height = obs_width = 2 * self.vision_radius + 1\n",
    "\n",
    "        self.living_penalty = 0.03  # tiny cost per step to discourage camping\n",
    "\n",
    "        # Each cell is one of: empty space (' '), planet ('#'), visited planet ('.'), start ('S'), RepublicShip ('R')\n",
    "        # Map characters as integers → you can define a vocab for it\n",
    "        self.char_to_int = {' ': 0, '#': 1, '.': 2, 'S': 3, 'R': 4}\n",
    "\n",
    "        # Observation: local grid (3x3) with integer values, plus mission time\n",
    "        self.observation_space = Dict({\n",
    "            \"vision\"       : Box(low=0,   high=4,         shape=(obs_height, obs_width), dtype=np.uint8),\n",
    "            \"danger\"       : Box(low=0.0, high=1.0,       shape=(obs_height, obs_width), dtype=np.float32),\n",
    "            \"reward_memory\": Box(low=0.0, high=np.inf,    shape=(obs_height, obs_width), dtype=np.float32)\n",
    "        })\n",
    "        \n",
    "\n",
    "        #  --- mission state -----------------------------------------------\n",
    "        self.mission_time_before_self_destruct = 1000\n",
    "\n",
    "        # To be used in reward function to give the RL agent a reward for seeing an unexplored pixel\n",
    "        # for the first time. Creating a copy of the map to mark regions that are seen or not.\n",
    "        self.seen_map = np.zeros((self.num_rows, self.num_cols), dtype=bool)\n",
    "        self.agent_damage_taken = False\n",
    "        self.damages = 0  # counts number of times agent has been damaged\n",
    "\n",
    "\n",
    "        # --- entities -----------------------------------------------------\n",
    "        self.entities = []               # list of ALL MobileEntity\n",
    "        self.agent = self                # optional alias if you treat env as agent wrapper\n",
    "        self.entity_mgr = EntityManager(self, n_rep=self.n_rep, n_sep=self.n_sep)     # define number of 'SeparatistShips' and 'RepublicShips' being created\n",
    "\n",
    "\n",
    "        # --- persistent maps -------------------------------------------------\n",
    "        self.discovered_planet = np.zeros((self.num_rows, self.num_cols), dtype=bool)\n",
    "        self.planet_reward_map = np.zeros((self.num_rows, self.num_cols), dtype=np.float32)\n",
    "\n",
    "        # tunables\n",
    "        self.planet_reward_scale = 5.0     # reward at the planet tile itself\n",
    "        self.planet_reward_decay = 1.5     # larger → slower fall-off\n",
    "\n",
    "\n",
    "        # --- pygame -----------------------------------------------\n",
    "        pygame.init()\n",
    "        self.cell_size = 20  # reduce cell size to fit 40x40 on screen\n",
    "        self.screen = pygame.display.set_mode(\n",
    "            (self.num_cols * self.cell_size, self.num_rows * self.cell_size)\n",
    "        )\n",
    "        pygame.display.set_caption(\"Star Wars Galaxy Explorer (Phase 2)\")\n",
    "\n",
    "\n",
    "    ####################\n",
    "    # Helper functions #\n",
    "    ####################\n",
    "    def generate_map(self, rows=40, cols=40, num_planets=20):\n",
    "        map = np.full((rows, cols), \" \", dtype='<U1')\n",
    "\n",
    "        # Randomly choose N planet positions (excluding start) and keeping the number of planets in each\n",
    "        # episode constant\n",
    "        available_positions = [(i, j) for i in range(rows) for j in range(cols) if (i, j) != (39, 21)]\n",
    "        planet_positions = random.sample(available_positions, num_planets)\n",
    "\n",
    "        for i, j in planet_positions:\n",
    "            map[i, j] = '#'\n",
    "\n",
    "        map[39, 21] = 'S'\n",
    "        return map\n",
    "\n",
    "    def get_RL_agent_local_observation(self):\n",
    "        r, c = self.state\n",
    "        v = self.vision_radius\n",
    "        size = 2*v + 1\n",
    "\n",
    "        obs = np.zeros((size, size), dtype=np.uint8)\n",
    "        rm  = np.zeros_like(obs, dtype=np.float32)\n",
    "        dang = np.zeros_like(obs, dtype=np.float32)\n",
    "\n",
    "        # --- a. vision -------------------------------\n",
    "        for dr in range(-v, v + 1):\n",
    "            for dc in range(-v, v + 1):\n",
    "                rr, cc = r + dr, c + dc\n",
    "                if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                    cell_char = self.map[rr, cc]\n",
    "                    obs[dr + v, dc + v] = self.char_to_int.get(cell_char, 0)\n",
    "                else:\n",
    "                    obs[dr + v, dc + v] = 0\n",
    "\n",
    "        # --- b. transient danger map -------------------------------------\n",
    "        for ship in self.entities:\n",
    "            if not isinstance(ship, SeperatistShip):\n",
    "                continue\n",
    "            sr, sc = ship.pos\n",
    "            # relative position of the ship w.r.t agent\n",
    "            rel_r, rel_c = sr - r + v, sc - c + v\n",
    "            if not (0 <= rel_r < size and 0 <= rel_c < size):\n",
    "                continue           # ship is outside vision → no penalty\n",
    "\n",
    "            for dr in range(-v, v + 1):\n",
    "                for dc in range(-v, v + 1):\n",
    "                    dist = abs(dr) + abs(dc)          # Manhattan distance\n",
    "                    if dist > v:                      # outside view\n",
    "                        continue\n",
    "                    # heavier penalty near the ship, linearly decaying\n",
    "                    penalty = (v - dist + 1) / (v + 1)    # 1.0 at dis = 0 → ≈ 0.09 at edge\n",
    "                    cell_r, cell_c = rel_r + dr, rel_c + dc\n",
    "                    if 0 <= cell_r < size and 0 <= cell_c < size:\n",
    "                        penalty = (v - dist + 1) / (v + 1)\n",
    "                        dang[cell_r, cell_c] = max(dang[cell_r, cell_c], penalty)\n",
    "\n",
    "        # --- c. reward memory map -------------------------------\n",
    "        for dr in range(-v, v + 1):\n",
    "            for dc in range(-v, v + 1):\n",
    "                rr, cc = r + dr, c + dc\n",
    "                if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                    rm[dr+v, dc+v] = self.planet_reward_map[rr, cc]\n",
    "\n",
    "        # --- d. show RepublicShips  -------------------------------------\n",
    "        for ship in self.entities:\n",
    "            if isinstance(ship, RepublicShip):\n",
    "                sr, sc = ship.pos              # ship row / col on the big map\n",
    "                rel_r, rel_c = sr - r + v, sc - c + v   # coordinates inside vision window\n",
    "                if 0 <= rel_r < size and 0 <= rel_c < size:\n",
    "                    obs[rel_r, rel_c] = self.char_to_int['R']\n",
    "\n",
    "        return {\n",
    "            \"vision\": obs,          # Current visual snapshot (local terrain)\n",
    "            \"danger\": dang,         # Danger map \n",
    "            \"reward_memory\": rm     # Agent's remembered \"explored\" map\n",
    "        }\n",
    "    \n",
    "    def _inject_planet_reward(self, pos, sign=+1.0):\n",
    "        \"\"\"Add (+1) or remove (−1) this planet’s contribution from planet_reward_map.\"\"\"\n",
    "        pr, pc = pos\n",
    "        for r in range(self.num_rows):\n",
    "            for c in range(self.num_cols):\n",
    "                dist = abs(pr - r) + abs(pc - c)   # Manhattan\n",
    "                contrib = sign * self.planet_reward_scale / (1.0 + self.planet_reward_decay*dist)\n",
    "                self.planet_reward_map[r, c] += contrib\n",
    "    \n",
    "    def check_valid_position(self, position):\n",
    "        row, col = position\n",
    "\n",
    "        # If RL agent goes out of the map\n",
    "        if row < 0 or col < 0 or row >= self.num_rows or col >= self.num_cols:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    def is_adjacent(self, pos1, pos2):\n",
    "        r1, c1 = pos1\n",
    "        r2, c2 = pos2\n",
    "        return (abs(r1 - r2) == 1 and c1 == c2) or (r1 == r2 and abs(c1 - c2) == 1)\n",
    "\n",
    "\n",
    "    ###############################################################\n",
    "    # OpenAI Gymnasium and Stable Baselines3's required functions #\n",
    "    ###############################################################\n",
    "    def step(self, action):\n",
    "        # --- Decrease 'mission_time_before_self_destruct' time -------------------------------------\n",
    "        self.mission_time_before_self_destruct -= 1\n",
    "\n",
    "        # --- Apply RL agent action -----------------------------------------------------------------\n",
    "        new_pos = np.array(self.state)\n",
    "        if action == 0:     # Forward\n",
    "            new_pos[0] -= 1\n",
    "        elif action == 1:   # Backward\n",
    "            new_pos[0] += 1\n",
    "        elif action == 2:   # Leftward\n",
    "            new_pos[1] -= 1 \n",
    "        elif action == 3:   # Rightward\n",
    "            new_pos[1] += 1\n",
    "\n",
    "        # Check if RL agent is in a valid position\n",
    "        if self.check_valid_position(new_pos):\n",
    "            if all(tuple(new_pos) != e.pos for e in self.entities):\n",
    "                self.state = tuple(new_pos)\n",
    "\n",
    "        #########################################\n",
    "        # Calculate Reward with Reward Function #\n",
    "        #########################################\n",
    "        reward = 0\n",
    "\n",
    "        row, col = self.state\n",
    "        r, c     = self.state\n",
    "        v        = self.vision_radius\n",
    "\n",
    "        exploration_reward = 0\n",
    "\n",
    "        # --- Penalise points for living -------------------------------------\n",
    "        reward -= self.living_penalty\n",
    "\n",
    "        # --- Reward points for every planet visited -------------------------------------\n",
    "        if self.map[row, col] == '#':       # If a planet is visited\n",
    "            self._inject_planet_reward((row, col), sign=-1.0)  # erase its halo\n",
    "            reward += 50\n",
    "            self.map[row, col] = '.'        # Mark planet as visited, so RL agent dosent choose to stay there infinitely and force it to find other planets\n",
    "            self.visited_planets += 1\n",
    "\n",
    "        # --- Penalise points if agent steps into a previously seen region or at the starting position --------------------\n",
    "        if self.seen_map[row, col]:  # already seen\n",
    "            reward -= 0.3\n",
    "\n",
    "        # Penalty for stepping back onto the starting position\n",
    "        if (row, col) == self.start_position:\n",
    "            reward -= 0.3\n",
    "\n",
    "        # --- Penalise points for revisitng an already visited planet -------------------------------------\n",
    "        if self.map[row, col] == '.':\n",
    "            reward -= 1.0  # or some stronger penalty\n",
    "\n",
    "        # --- Reward points for newly explored (first-time seen) cells in vision --------------------------\n",
    "        for dr in range(-v, v + 1):\n",
    "            for dc in range(-v, v + 1):\n",
    "                rr, cc = r + dr, c + dc\n",
    "                if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                    if not self.seen_map[rr, cc]:\n",
    "                        self.seen_map[rr, cc] = True\n",
    "                        exploration_reward += 0.3  # reward per new cell seen\n",
    "\n",
    "        # Discover new planets that just entered vision\n",
    "        for dr in range(-v, v + 1):\n",
    "            for dc in range(-v, v + 1):\n",
    "                rr, cc = r + dr, c + dc\n",
    "                if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                    if self.map[rr, cc] == '#' and not self.discovered_planet[rr, cc]:\n",
    "                        self.discovered_planet[rr, cc] = True\n",
    "                        self._inject_planet_reward((rr, cc), sign=+1.0)   # add its reward field\n",
    "        \n",
    "        reward += exploration_reward * 1.5\n",
    "        reward += self.planet_reward_map[row, col]        # dense, cumulative\n",
    "\n",
    "        # --- Penalise points for camping near a corner (2x2 area) -------------------------------------\n",
    "        if (row <= 1 and col <= 1) or \\\n",
    "        (row <= 1 and col >= self.num_cols - 2) or \\\n",
    "        (row >= self.num_rows - 2 and col <= 1) or \\\n",
    "        (row >= self.num_rows - 2 and col >= self.num_cols - 2):\n",
    "            reward -= 0.1\n",
    "\n",
    "        #######################################################################################################\n",
    "        # Handling movement logic and rewards/penalty points related to 'SeparatistShips' and 'RepublicShips' #\n",
    "        #######################################################################################################\n",
    "        # --- a. Move NPCs ('SeparatistShips' and 'RepublicShips') -------------------------------------\n",
    "        proposals = {}   # pos -> entity list\n",
    "        for e in self.entities:\n",
    "            move = e.choose_action_stochastic(self)\n",
    "            new_pos = e.propose_move(move)\n",
    "            # keep inside bounds\n",
    "            r,c = new_pos\n",
    "            if not (0 <= r < self.num_rows and 0 <= c < self.num_cols):\n",
    "                new_pos = e.pos               # bounce\n",
    "            proposals.setdefault(new_pos, []).append(e)\n",
    "\n",
    "        # --- b. Resolve collisions (single occupant rule + adjacency kill) -------------------------------------\n",
    "        #   * single occupant rule\n",
    "        #   * tie‑breaker: Separatist ⇒ victory & occupies; Republic damaged\n",
    "        #   * Republic–Republic collision → first moves, others stay\n",
    "        survivors = []\n",
    "        for dest, group in proposals.items():\n",
    "\n",
    "            if dest == self.state:\n",
    "                survivors.extend(group)        # everyone stays where they are\n",
    "                continue\n",
    "\n",
    "            if len(group) == 1 and dest != self.state:  # free cell\n",
    "                group[0].pos = dest\n",
    "                survivors.append(group[0])\n",
    "                continue\n",
    "\n",
    "            # multiple claimants → resolve\n",
    "            seps = [g for g in group if isinstance(g, SeperatistShip)]\n",
    "            reps = [g for g in group if isinstance(g, RepublicShip)]\n",
    "\n",
    "            if seps:  # at least one Separatist present\n",
    "                # damage republic ships in that cell\n",
    "                for rep in reps:\n",
    "                    continue  # simply omit from survivors list\n",
    "                # one separatist (priority) takes the cell, the rest stay put\n",
    "                seps[0].pos = dest\n",
    "                survivors.extend(seps)  # all separatists survive (only first moved)\n",
    "            else:    # only republics vying for cell\n",
    "                chosen = random.choice(group)\n",
    "                chosen.pos = dest\n",
    "                survivors.append(chosen)\n",
    "                survivors.extend([g for g in group if g is not chosen])\n",
    "\n",
    "        # Updating surviving entities\n",
    "        self.entities = survivors\n",
    "\n",
    "        # 'SeparatistShip' damage 'RepublicShip' or RL agent by neighbouring\n",
    "        to_remove = []\n",
    "        for sep in (e for e in self.entities if isinstance(e, SeperatistShip)):\n",
    "            for rep in (e for e in self.entities if isinstance(e, RepublicShip)):\n",
    "                if self.is_adjacent(sep.pos, rep.pos):\n",
    "                    to_remove.append(rep)\n",
    "            \n",
    "            # Check if RL agent is adjacent to Separatist\n",
    "            if self.is_adjacent(sep.pos, self.state):\n",
    "                self.agent_damage_taken = True\n",
    "                self.damages += 1\n",
    "\n",
    "        for rep in to_remove:\n",
    "            if rep in self.entities:\n",
    "                self.entities.remove(rep)\n",
    "\n",
    "        # --- c. Penalise points for directly adjacent/neighbouring a 'SeparatistShip' (agent takes damage) ----------------------\n",
    "        if self.agent_damage_taken:\n",
    "            reward -= 30\n",
    "            self.agent_damage_taken = False\n",
    "            # done = True\n",
    "\n",
    "\n",
    "        ####################################################################################\n",
    "        # Handling danger map logic, where when a 'SeparatistShip' enters a agent's vision #\n",
    "        ####################################################################################\n",
    "        # --- Penalise points for 'seeing' a 'SeparatistShip' in their vision to encourage/get them to stay away ----------------------\n",
    "        # a. Build the transient danger map exactly as in get_RL_agent_local_observation\n",
    "        #    (you may move that code into a helper so you don't duplicate it).\n",
    "        dang = np.zeros((2*v+1, 2*v+1), dtype=np.float32)\n",
    "        for ship in self.entities:\n",
    "            if not isinstance(ship, SeperatistShip):\n",
    "                continue\n",
    "            sr, sc = ship.pos\n",
    "            rel_r, rel_c = sr - r + v, sc - c + v\n",
    "            if 0 <= rel_r < 2*v+1 and 0 <= rel_c < 2*v+1:\n",
    "                for dr in range(-v, v + 1):\n",
    "                    for dc in range(-v, v + 1):\n",
    "                        dist = abs(dr) + abs(dc)\n",
    "                        if dist > v:\n",
    "                            continue\n",
    "\n",
    "                        cell_r = rel_r + dr\n",
    "                        cell_c = rel_c + dc\n",
    "\n",
    "                        if 0 <= cell_r < 2*v+1 and 0 <= cell_c < 2*v+1:\n",
    "                            penalty = (v - dist + 1) / (v + 1)\n",
    "                            dang[cell_r, cell_c] = max(dang[cell_r, cell_c], penalty)\n",
    "\n",
    "        # b. Convert that map into a negative reward every step.\n",
    "        #    Two common choices:   (pick ONE)\n",
    "        #    • sum of penalties in the window   → harsher when surrounded\n",
    "        #    • max penalty (nearest threat)     → distance-only\n",
    "        danger_strength = np.max(dang)        # np.sum(dang) or np.max(dang)\n",
    "        danger_scale    = -0.3                # tune sign & magnitude\n",
    "\n",
    "        reward += danger_scale * danger_strength\n",
    "\n",
    "\n",
    "        if self.mission_time_before_self_destruct <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        truncated = False\n",
    "        info = {\n",
    "            \"visited_planets\": self.visited_planets,\n",
    "            \"total_planets\": self.total_planets,\n",
    "            \"damages\": self.damages\n",
    "        }\n",
    "\n",
    "        return self.get_RL_agent_local_observation(), reward, done, truncated, info\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        # Clear the screen\n",
    "        self.screen.fill((255, 255, 255))  \n",
    "\n",
    "        agent_r, agent_c = self.state\n",
    "        v = self.vision_radius\n",
    "\n",
    "        # Draw env elements one cell at a time\n",
    "        for row in range(self.num_rows):\n",
    "            for col in range(self.num_cols):\n",
    "                cell_left = col * self.cell_size\n",
    "                cell_top = row * self.cell_size\n",
    "\n",
    "                # If seen_map is True and it's just empty space (i.e. not a planet or visited)\n",
    "                if self.seen_map[row, col] and self.map[row, col] == ' ':\n",
    "                    pygame.draw.rect(self.screen, (255, 200, 200), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "\n",
    "                # Draw the vision radius in yellow (as a background highlight)\n",
    "                if abs(row - agent_r) <= v and abs(col - agent_c) <= v:\n",
    "                    pygame.draw.rect(self.screen, (255, 255, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "\n",
    "                if self.map[row, col] == '#':  # Draw non-visited planet in Light Blue\n",
    "                    pygame.draw.rect(self.screen, (173, 216, 230), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                elif self.map[row, col] == '.':  # Draw visited planet in Green\n",
    "                    pygame.draw.rect(self.screen, (0, 255, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                elif self.map[row, col] == 'S':  # Draw starting position in Black\n",
    "                    pygame.draw.rect(self.screen, (0, 0, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "\n",
    "                if (row, col) == self.state:  # Draw RL agent position in Gray\n",
    "                    pygame.draw.rect(self.screen, (125, 125, 125), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "\n",
    "        # Draw 'SeparatistShips' and 'RepublicShips'\n",
    "        for ship in self.entities:\n",
    "            sr, sc = ship.pos\n",
    "            color = (255,0,0) if isinstance(ship, SeperatistShip) else (0,0,255)\n",
    "            pygame.draw.rect(self.screen, color,\n",
    "                            (sc*self.cell_size, sr*self.cell_size,\n",
    "                            self.cell_size, self.cell_size))\n",
    "\n",
    "        # === Highlight vision radius of each RepublicShip (NEUTRAL ZONE) ===\n",
    "        for ship in self.entities:\n",
    "            if isinstance(ship, RepublicShip):\n",
    "                sr, sc = ship.pos\n",
    "                vr = ship.vision_radius\n",
    "                for dr in range(-vr, vr + 1):\n",
    "                    for dc in range(-vr, vr + 1):\n",
    "                        rr, cc = sr + dr, sc + dc\n",
    "                        if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                            left = cc * self.cell_size\n",
    "                            top  = rr * self.cell_size\n",
    "                            pygame.draw.rect(self.screen, (0, 0, 255), (left, top, self.cell_size, self.cell_size), width=1)\n",
    "\n",
    "        # === Highlight vision radius of each SeperatistShip (DANGER ZONE) ===\n",
    "        for ship in self.entities:\n",
    "            if isinstance(ship, SeperatistShip):\n",
    "                sr, sc = ship.pos\n",
    "                vr = ship.vision_radius\n",
    "                for dr in range(-vr, vr + 1):\n",
    "                    for dc in range(-vr, vr + 1):\n",
    "                        rr, cc = sr + dr, sc + dc\n",
    "                        if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                            left = cc * self.cell_size\n",
    "                            top  = rr * self.cell_size\n",
    "                            pygame.draw.rect(self.screen, (255, 0, 0), (left, top, self.cell_size, self.cell_size), width=1)\n",
    "\n",
    "        pygame.display.update()  # Update the display\n",
    "        # pygame.time.delay(50)   # Slow down the rendering\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        # --- Generate a new map ------------------------------------------------------------------------\n",
    "        self.map = self.generate_map(rows=40, cols=40, num_planets=20)\n",
    "\n",
    "        # --- Reinitialize dependent properties ---------------------------------------------------------\n",
    "        self.num_rows, self.num_cols = self.map.shape\n",
    "        self.seen_map[:]           = False\n",
    "        self.discovered_planet[:]  = False \n",
    "        self.planet_reward_map[:]  = 0.0   \n",
    "        \n",
    "        self.start_position = tuple(np.argwhere(self.map == 'S')[0])\n",
    "        self.state = self.start_position\n",
    "        self.mission_time_before_self_destruct = 1000\n",
    "        self.agent_damage_taken = False\n",
    "        self.damages = 0\n",
    "\n",
    "        self.total_planets = np.sum(self.map == '#')\n",
    "        self.visited_planets = 0\n",
    "\n",
    "        self.entities = []\n",
    "        self.entity_mgr = EntityManager(self, n_rep=self.n_sep, n_sep=self.n_sep)\n",
    "\n",
    "\n",
    "        # --- Update Pygame screen if dimensions changed ------------------------------------------------\n",
    "        self.screen = pygame.display.set_mode(\n",
    "            (self.num_cols * self.cell_size, self.num_rows * self.cell_size)\n",
    "        )\n",
    "\n",
    "        info = {}\n",
    "        return self.get_RL_agent_local_observation(), info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7f7c3",
   "metadata": {},
   "source": [
    "### Testing the Outer Rim RL Environment if it works with a baseline algorithm that takes random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202b1257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 | Score: 291.00 | Planets Found: 1/20 | Damages: 49\n",
      "Episode: 2 | Score: 1623.96 | Planets Found: 4/20 | Damages: 6\n",
      "Episode: 3 | Score: 1005.92 | Planets Found: 3/20 | Damages: 47\n",
      "Episode: 4 | Score: -4210.89 | Planets Found: 4/20 | Damages: 194\n",
      "Episode: 5 | Score: 774.89 | Planets Found: 4/20 | Damages: 27\n"
     ]
    }
   ],
   "source": [
    "env = OuterRimEnv(2,2)\n",
    "\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    # Initialise starting state of the RL agent in the RL Environment before an episode, done to false, and starting \n",
    "    # episode score to 0\n",
    "    obs, _ = env.reset()\n",
    "    # print(f\"Initial State: {obs}\")\n",
    "    done = False\n",
    "    episode_score = 0\n",
    "\n",
    "    # During an episode:\n",
    "    while not done:\n",
    "        env.render()\n",
    "        # RL agent determines action to take\n",
    "        # - In this case, we are randomly sampling an action to take by our RL agent in the RL Environment (this line of\n",
    "        #   code defines that baseline algorithm that takes random actions (instead of an RL algorithm))\n",
    "        action = env.action_space.sample()\n",
    "        # RL Environment generates the next state and reward gained upon taking the action in the current state\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        # Append the reward gained upon taking the action in the current state to the cumulative episode date\n",
    "        episode_score += reward\n",
    "\n",
    "    print(f\"Episode: {episode} | Score: {episode_score:.2f} | Planets Found: {info['visited_planets']}/{info['total_planets']} | Damages: {info['damages']}\")\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16aa0bc",
   "metadata": {},
   "source": [
    "## Train a PPO DRL algorithm in a RL Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da52238",
   "metadata": {},
   "source": [
    "### Vectorising and Normalising rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87e03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: OuterRimEnv(2, 2)])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_reward=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ad83f",
   "metadata": {},
   "source": [
    "### For logging purposes of the training process of the PPO DRL algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ca12d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Star_Wars_Galaxy_Phase_2\\logs\n"
     ]
    }
   ],
   "source": [
    "# Stating the path where we want to store our training logs files in the local folder './Training_Project_3_Custom/logs'\n",
    "log_path = os.path.join('Training_Star_Wars_Galaxy_Phase_2', 'logs')\n",
    "print(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d81e42",
   "metadata": {},
   "source": [
    "### Creating the PPO DRL algorithm in the RL Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5357ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# What does each of the parameters in the 'PPO' DRL algorithm class mean?\n",
    "# - 'policy' (e.g. 'MlpPolicy'  - refers to the learning architecture used a the policy of the RL algorithm, which in this\n",
    "#               or 'CnnPolicy')   is FNN/MLP\n",
    "# - 'env'                       - refers to the RL environment to train the RL algorithm in\n",
    "# - 'verbose'                   - controls how much information is printed to the console/log during training\n",
    "#                                 -> 'verbose=0' means 'Silent', no output at all\n",
    "#                                 -> 'verbose=1' means 'Info', shows key training events: episode rewards, updates, losses, etc.\n",
    "#                                 -> 'verbose=2' means 'Debug' shows more detailed info like hyperparameters, rollout steps, and internal logs\n",
    "# - 'tensorboard_log'           - states to do the training logging in Tensorboard\n",
    "PPO_DRL_model = PPO('MultiInputPolicy', \n",
    "                    env, \n",
    "                    verbose=1, \n",
    "                    tensorboard_log=log_path,\n",
    "                    normalize_advantage=True,\n",
    "                    ent_coef=0.02,\n",
    "                    gamma=0.98,\n",
    "                    n_steps=2048,\n",
    "                    gae_lambda=0.95\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c09c8c",
   "metadata": {},
   "source": [
    "### Training the PPO DRL algorithm in the RL Environment to become a PPO DRL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae7343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training_Star_Wars_Galaxy_Phase_2\\logs\\PPO_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 583  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 3    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 380        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07914759 |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.709     |\n",
      "|    explained_variance   | 0.432      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0847    |\n",
      "|    n_updates            | 2460       |\n",
      "|    policy_gradient_loss | -0.0556    |\n",
      "|    value_loss           | 0.0159     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.067106664 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0943     |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    value_loss           | 0.017       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060928874 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0794     |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.0488     |\n",
      "|    value_loss           | 0.0187      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 340        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07673482 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.691     |\n",
      "|    explained_variance   | 0.726      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.074     |\n",
      "|    n_updates            | 2490       |\n",
      "|    policy_gradient_loss | -0.0565    |\n",
      "|    value_loss           | 0.0166     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 338         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.081646815 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0798     |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 0.0301      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 323        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08097124 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.593     |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0991    |\n",
      "|    n_updates            | 2510       |\n",
      "|    policy_gradient_loss | -0.0595    |\n",
      "|    value_loss           | 0.0194     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06433851 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.711     |\n",
      "|    explained_variance   | 0.616      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.113     |\n",
      "|    n_updates            | 2520       |\n",
      "|    policy_gradient_loss | -0.0585    |\n",
      "|    value_loss           | 0.0153     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.084734574 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.743      |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.108      |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 312        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06343196 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.752     |\n",
      "|    explained_variance   | 0.7        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.1       |\n",
      "|    n_updates            | 2540       |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.0217     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.079761915 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.671      |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0742     |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.0498     |\n",
      "|    value_loss           | 0.0214      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053752832 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.769      |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0707     |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 0.0179      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039909624 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.95       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0979     |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.00964     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061009064 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.088      |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.0504     |\n",
      "|    value_loss           | 0.0278      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 313       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0936993 |\n",
      "|    clip_fraction        | 0.348     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.66     |\n",
      "|    explained_variance   | 0.539     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.105    |\n",
      "|    n_updates            | 2590      |\n",
      "|    policy_gradient_loss | -0.0616   |\n",
      "|    value_loss           | 0.0238    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 309       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0529029 |\n",
      "|    clip_fraction        | 0.318     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.812    |\n",
      "|    explained_variance   | 0.655     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0918   |\n",
      "|    n_updates            | 2600      |\n",
      "|    policy_gradient_loss | -0.0495   |\n",
      "|    value_loss           | 0.0153    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 111        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06227365 |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.762     |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0974    |\n",
      "|    n_updates            | 2610       |\n",
      "|    policy_gradient_loss | -0.0522    |\n",
      "|    value_loss           | 0.0181     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061479446 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.787      |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0698     |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | -0.0497     |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 315       |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 123       |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0644761 |\n",
      "|    clip_fraction        | 0.296     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.837    |\n",
      "|    explained_variance   | 0.73      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0664   |\n",
      "|    n_updates            | 2630      |\n",
      "|    policy_gradient_loss | -0.0526   |\n",
      "|    value_loss           | 0.0128    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06368156 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.733     |\n",
      "|    explained_variance   | 0.846      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0818    |\n",
      "|    n_updates            | 2640       |\n",
      "|    policy_gradient_loss | -0.0464    |\n",
      "|    value_loss           | 0.0107     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 138        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08269538 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.676     |\n",
      "|    explained_variance   | 0.424      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0882    |\n",
      "|    n_updates            | 2650       |\n",
      "|    policy_gradient_loss | -0.0614    |\n",
      "|    value_loss           | 0.0176     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08658276 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.571     |\n",
      "|    explained_variance   | 0.529      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.11      |\n",
      "|    n_updates            | 2660       |\n",
      "|    policy_gradient_loss | -0.0545    |\n",
      "|    value_loss           | 0.0169     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058508597 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0801     |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 0.0244      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 158        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09619963 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.725     |\n",
      "|    explained_variance   | 0.549      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0829    |\n",
      "|    n_updates            | 2680       |\n",
      "|    policy_gradient_loss | -0.0487    |\n",
      "|    value_loss           | 0.0129     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05804493 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.827     |\n",
      "|    explained_variance   | 0.591      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0856    |\n",
      "|    n_updates            | 2690       |\n",
      "|    policy_gradient_loss | -0.0398    |\n",
      "|    value_loss           | 0.0215     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 173        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12573574 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.602     |\n",
      "|    explained_variance   | 0.785      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0716    |\n",
      "|    n_updates            | 2700       |\n",
      "|    policy_gradient_loss | -0.0391    |\n",
      "|    value_loss           | 0.00943    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040380403 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0643     |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 301        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 190        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07088944 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.787     |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0813    |\n",
      "|    n_updates            | 2720       |\n",
      "|    policy_gradient_loss | -0.0497    |\n",
      "|    value_loss           | 0.0154     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 299        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 198        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06889243 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.656     |\n",
      "|    explained_variance   | 0.626      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0272    |\n",
      "|    n_updates            | 2730       |\n",
      "|    policy_gradient_loss | -0.0457    |\n",
      "|    value_loss           | 0.0896     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.068170585 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0885     |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    value_loss           | 0.0135      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057463594 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.65       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0247     |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.065852694 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.691      |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0978     |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 0.0101      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054100536 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.055      |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 0.0162      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063745424 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0315     |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    value_loss           | 0.0115      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 294        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 243        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06650246 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.617     |\n",
      "|    explained_variance   | 0.86       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0427    |\n",
      "|    n_updates            | 2790       |\n",
      "|    policy_gradient_loss | -0.0456    |\n",
      "|    value_loss           | 0.00899    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 251        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08860354 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.607     |\n",
      "|    explained_variance   | 0.758      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.076     |\n",
      "|    n_updates            | 2800       |\n",
      "|    policy_gradient_loss | -0.0475    |\n",
      "|    value_loss           | 0.0135     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 259        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08154875 |\n",
      "|    clip_fraction        | 0.367      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.635     |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0783    |\n",
      "|    n_updates            | 2810       |\n",
      "|    policy_gradient_loss | -0.06      |\n",
      "|    value_loss           | 0.0139     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 267        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07397391 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.597     |\n",
      "|    explained_variance   | 0.463      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0639    |\n",
      "|    n_updates            | 2820       |\n",
      "|    policy_gradient_loss | -0.0557    |\n",
      "|    value_loss           | 0.0144     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 276        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08349886 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.581     |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0756    |\n",
      "|    n_updates            | 2830       |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.00922    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.074190415 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.767      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0509     |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    value_loss           | 0.00882     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060228143 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0896     |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 0.00752     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.093312666 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.7        |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0664     |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.0515     |\n",
      "|    value_loss           | 0.0131      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 289       |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 303       |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0687355 |\n",
      "|    clip_fraction        | 0.261     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.852    |\n",
      "|    explained_variance   | 0.795     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.077    |\n",
      "|    n_updates            | 2870      |\n",
      "|    policy_gradient_loss | -0.0476   |\n",
      "|    value_loss           | 0.0126    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057976313 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.764      |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0635     |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.0554     |\n",
      "|    value_loss           | 0.0117      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 319        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13185903 |\n",
      "|    clip_fraction        | 0.382      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.708     |\n",
      "|    explained_variance   | 0.652      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.123     |\n",
      "|    n_updates            | 2890       |\n",
      "|    policy_gradient_loss | -0.0546    |\n",
      "|    value_loss           | 0.0121     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 324        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07181061 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.771     |\n",
      "|    explained_variance   | 0.784      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0967    |\n",
      "|    n_updates            | 2900       |\n",
      "|    policy_gradient_loss | -0.0578    |\n",
      "|    value_loss           | 0.0128     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.073454134 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0788     |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.0504     |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 338        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15893692 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.515     |\n",
      "|    explained_variance   | 0.81       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0889    |\n",
      "|    n_updates            | 2920       |\n",
      "|    policy_gradient_loss | -0.0424    |\n",
      "|    value_loss           | 0.0138     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 345        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08008672 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.58      |\n",
      "|    explained_variance   | 0.658      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0899    |\n",
      "|    n_updates            | 2930       |\n",
      "|    policy_gradient_loss | -0.054     |\n",
      "|    value_loss           | 0.0168     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042133607 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.822      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.102      |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 0.0119      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 358        |\n",
      "|    total_timesteps      | 104448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06768839 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.897     |\n",
      "|    explained_variance   | 0.716      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0784    |\n",
      "|    n_updates            | 2950       |\n",
      "|    policy_gradient_loss | -0.0438    |\n",
      "|    value_loss           | 0.0079     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 366        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06568821 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.762     |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.108     |\n",
      "|    n_updates            | 2960       |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.0177     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 376        |\n",
      "|    total_timesteps      | 108544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06316301 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.697     |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0931    |\n",
      "|    n_updates            | 2970       |\n",
      "|    policy_gradient_loss | -0.0469    |\n",
      "|    value_loss           | 0.0123     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 384         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.074628815 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0701     |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.0553     |\n",
      "|    value_loss           | 0.0237      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 390        |\n",
      "|    total_timesteps      | 112640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05680828 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.658     |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0912    |\n",
      "|    n_updates            | 2990       |\n",
      "|    policy_gradient_loss | -0.0472    |\n",
      "|    value_loss           | 0.0194     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 397         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055025738 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0795     |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 288       |\n",
      "|    iterations           | 57        |\n",
      "|    time_elapsed         | 404       |\n",
      "|    total_timesteps      | 116736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0607084 |\n",
      "|    clip_fraction        | 0.288     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.688    |\n",
      "|    explained_variance   | 0.795     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0516   |\n",
      "|    n_updates            | 3010      |\n",
      "|    policy_gradient_loss | -0.0358   |\n",
      "|    value_loss           | 0.00671   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054036483 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.96       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0577     |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 0.00775     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 416        |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07662519 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.651     |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0704    |\n",
      "|    n_updates            | 3030       |\n",
      "|    policy_gradient_loss | -0.0463    |\n",
      "|    value_loss           | 0.0115     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 422        |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08365837 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.696     |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0591    |\n",
      "|    n_updates            | 3040       |\n",
      "|    policy_gradient_loss | -0.0525    |\n",
      "|    value_loss           | 0.0185     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 431        |\n",
      "|    total_timesteps      | 124928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09266041 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.638     |\n",
      "|    explained_variance   | 0.739      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0999    |\n",
      "|    n_updates            | 3050       |\n",
      "|    policy_gradient_loss | -0.0567    |\n",
      "|    value_loss           | 0.013      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 438        |\n",
      "|    total_timesteps      | 126976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07520008 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.619     |\n",
      "|    explained_variance   | 0.746      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0762    |\n",
      "|    n_updates            | 3060       |\n",
      "|    policy_gradient_loss | -0.0488    |\n",
      "|    value_loss           | 0.0129     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 447         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.075527996 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0708     |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.086319745 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0394     |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.0569     |\n",
      "|    value_loss           | 0.0389      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 462         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043569796 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0725     |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 469         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055801906 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.895      |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0713     |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 0.00699     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 477        |\n",
      "|    total_timesteps      | 137216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05333998 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.933     |\n",
      "|    explained_variance   | 0.81       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0904    |\n",
      "|    n_updates            | 3110       |\n",
      "|    policy_gradient_loss | -0.0404    |\n",
      "|    value_loss           | 0.0139     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.078449994 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0892     |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 0.0232      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.075548545 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0816     |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.0551     |\n",
      "|    value_loss           | 0.0275      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 499        |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07583985 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.707     |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.111     |\n",
      "|    n_updates            | 3140       |\n",
      "|    policy_gradient_loss | -0.0575    |\n",
      "|    value_loss           | 0.018      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 507        |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06694895 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.627     |\n",
      "|    explained_variance   | 0.609      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 3150       |\n",
      "|    policy_gradient_loss | -0.0554    |\n",
      "|    value_loss           | 0.0145     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 515        |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07192209 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.717     |\n",
      "|    explained_variance   | 0.775      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0805    |\n",
      "|    n_updates            | 3160       |\n",
      "|    policy_gradient_loss | -0.0466    |\n",
      "|    value_loss           | 0.00881    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.069037735 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.649      |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.067      |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    value_loss           | 0.032       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 530        |\n",
      "|    total_timesteps      | 151552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07479746 |\n",
      "|    clip_fraction        | 0.378      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.653      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.051     |\n",
      "|    n_updates            | 3180       |\n",
      "|    policy_gradient_loss | -0.0486    |\n",
      "|    value_loss           | 0.0174     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 538        |\n",
      "|    total_timesteps      | 153600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06870997 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.586     |\n",
      "|    explained_variance   | 0.435      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.08      |\n",
      "|    n_updates            | 3190       |\n",
      "|    policy_gradient_loss | -0.0558    |\n",
      "|    value_loss           | 0.0171     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 546        |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04918855 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.758     |\n",
      "|    explained_variance   | 0.672      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0568    |\n",
      "|    n_updates            | 3200       |\n",
      "|    policy_gradient_loss | -0.0376    |\n",
      "|    value_loss           | 0.0178     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 554        |\n",
      "|    total_timesteps      | 157696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05578479 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.628     |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0869    |\n",
      "|    n_updates            | 3210       |\n",
      "|    policy_gradient_loss | -0.0427    |\n",
      "|    value_loss           | 0.0209     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 562        |\n",
      "|    total_timesteps      | 159744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06207637 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.759     |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0705    |\n",
      "|    n_updates            | 3220       |\n",
      "|    policy_gradient_loss | -0.0494    |\n",
      "|    value_loss           | 0.0157     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 571        |\n",
      "|    total_timesteps      | 161792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09001327 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.648     |\n",
      "|    explained_variance   | 0.691      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 3230       |\n",
      "|    policy_gradient_loss | -0.0494    |\n",
      "|    value_loss           | 0.0152     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 578         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.095438845 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0958     |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.0563     |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 282       |\n",
      "|    iterations           | 81        |\n",
      "|    time_elapsed         | 587       |\n",
      "|    total_timesteps      | 165888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0723294 |\n",
      "|    clip_fraction        | 0.288     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.693    |\n",
      "|    explained_variance   | 0.687     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0866   |\n",
      "|    n_updates            | 3250      |\n",
      "|    policy_gradient_loss | -0.0424   |\n",
      "|    value_loss           | 0.0162    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 594         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063082084 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0634     |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 0.0129      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 602        |\n",
      "|    total_timesteps      | 169984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05415396 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.834     |\n",
      "|    explained_variance   | 0.91       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0877    |\n",
      "|    n_updates            | 3270       |\n",
      "|    policy_gradient_loss | -0.0428    |\n",
      "|    value_loss           | 0.00781    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 84         |\n",
      "|    time_elapsed         | 608        |\n",
      "|    total_timesteps      | 172032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07116288 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.769     |\n",
      "|    explained_variance   | 0.778      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.103     |\n",
      "|    n_updates            | 3280       |\n",
      "|    policy_gradient_loss | -0.0359    |\n",
      "|    value_loss           | 0.00385    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 85         |\n",
      "|    time_elapsed         | 618        |\n",
      "|    total_timesteps      | 174080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04695739 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.756     |\n",
      "|    explained_variance   | 0.676      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0775    |\n",
      "|    n_updates            | 3290       |\n",
      "|    policy_gradient_loss | -0.041     |\n",
      "|    value_loss           | 0.0113     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 625        |\n",
      "|    total_timesteps      | 176128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06439681 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.588     |\n",
      "|    explained_variance   | 0.731      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0888    |\n",
      "|    n_updates            | 3300       |\n",
      "|    policy_gradient_loss | -0.0479    |\n",
      "|    value_loss           | 0.00869    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 632        |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06476365 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.751     |\n",
      "|    explained_variance   | 0.792      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0455    |\n",
      "|    n_updates            | 3310       |\n",
      "|    policy_gradient_loss | -0.045     |\n",
      "|    value_loss           | 0.00974    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 640        |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07351257 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.736     |\n",
      "|    explained_variance   | 0.799      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0227    |\n",
      "|    n_updates            | 3320       |\n",
      "|    policy_gradient_loss | -0.0486    |\n",
      "|    value_loss           | 0.0121     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 649        |\n",
      "|    total_timesteps      | 182272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08305918 |\n",
      "|    clip_fraction        | 0.485      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.689     |\n",
      "|    explained_variance   | 0.849      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.103     |\n",
      "|    n_updates            | 3330       |\n",
      "|    policy_gradient_loss | -0.0695    |\n",
      "|    value_loss           | 0.00903    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 655         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070208974 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0709     |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | -0.0485     |\n",
      "|    value_loss           | 0.0135      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 662        |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08737756 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.528     |\n",
      "|    explained_variance   | 0.584      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0421    |\n",
      "|    n_updates            | 3350       |\n",
      "|    policy_gradient_loss | -0.0468    |\n",
      "|    value_loss           | 0.0195     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 669        |\n",
      "|    total_timesteps      | 188416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08087568 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.595     |\n",
      "|    explained_variance   | 0.589      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 3360       |\n",
      "|    policy_gradient_loss | -0.0536    |\n",
      "|    value_loss           | 0.0184     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 677         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039909527 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.835      |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0341     |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.0151      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 684         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.083607905 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.598      |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0726     |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 0.0136      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 691        |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05838538 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.717     |\n",
      "|    explained_variance   | 0.749      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0741    |\n",
      "|    n_updates            | 3390       |\n",
      "|    policy_gradient_loss | -0.0351    |\n",
      "|    value_loss           | 0.0134     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 698         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.068445556 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.662      |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0577      |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 0.00942     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 706        |\n",
      "|    total_timesteps      | 198656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07699822 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.61      |\n",
      "|    explained_variance   | 0.688      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.104     |\n",
      "|    n_updates            | 3410       |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    value_loss           | 0.0198     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 714         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046715837 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.754      |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0779     |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 0.0152      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 720        |\n",
      "|    total_timesteps      | 202752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05877529 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.674     |\n",
      "|    explained_variance   | 0.748      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.107     |\n",
      "|    n_updates            | 3430       |\n",
      "|    policy_gradient_loss | -0.0495    |\n",
      "|    value_loss           | 0.00961    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 727        |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06753559 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.69      |\n",
      "|    explained_variance   | 0.788      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.107     |\n",
      "|    n_updates            | 3440       |\n",
      "|    policy_gradient_loss | -0.0394    |\n",
      "|    value_loss           | 0.0105     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 735        |\n",
      "|    total_timesteps      | 206848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09312956 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.689     |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0795    |\n",
      "|    n_updates            | 3450       |\n",
      "|    policy_gradient_loss | -0.0457    |\n",
      "|    value_loss           | 0.0141     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 102        |\n",
      "|    time_elapsed         | 743        |\n",
      "|    total_timesteps      | 208896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04336734 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.695     |\n",
      "|    explained_variance   | 0.696      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0764    |\n",
      "|    n_updates            | 3460       |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    value_loss           | 0.0182     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 750         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061654188 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0612     |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 0.00998     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 281       |\n",
      "|    iterations           | 104       |\n",
      "|    time_elapsed         | 757       |\n",
      "|    total_timesteps      | 212992    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1278146 |\n",
      "|    clip_fraction        | 0.427     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.603    |\n",
      "|    explained_variance   | 0.586     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0623   |\n",
      "|    n_updates            | 3480      |\n",
      "|    policy_gradient_loss | -0.0542   |\n",
      "|    value_loss           | 0.0134    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 280       |\n",
      "|    iterations           | 105       |\n",
      "|    time_elapsed         | 766       |\n",
      "|    total_timesteps      | 215040    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0772729 |\n",
      "|    clip_fraction        | 0.308     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.532    |\n",
      "|    explained_variance   | 0.503     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0905   |\n",
      "|    n_updates            | 3490      |\n",
      "|    policy_gradient_loss | -0.0494   |\n",
      "|    value_loss           | 0.0132    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 106        |\n",
      "|    time_elapsed         | 773        |\n",
      "|    total_timesteps      | 217088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07494597 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.66      |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0994    |\n",
      "|    n_updates            | 3500       |\n",
      "|    policy_gradient_loss | -0.0421    |\n",
      "|    value_loss           | 0.013      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 779         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046476595 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0734     |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 0.0138      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 786        |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05944697 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.64      |\n",
      "|    explained_variance   | 0.45       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0752    |\n",
      "|    n_updates            | 3520       |\n",
      "|    policy_gradient_loss | -0.0437    |\n",
      "|    value_loss           | 0.0173     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 793         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051755354 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0834     |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 0.0132      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 800         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030679025 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0616     |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 0.0056      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 807         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043223426 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.968      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0667     |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 0.0134      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 112        |\n",
      "|    time_elapsed         | 814        |\n",
      "|    total_timesteps      | 229376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07618481 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.675     |\n",
      "|    explained_variance   | 0.801      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0874    |\n",
      "|    n_updates            | 3560       |\n",
      "|    policy_gradient_loss | -0.0482    |\n",
      "|    value_loss           | 0.0131     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 820        |\n",
      "|    total_timesteps      | 231424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07290785 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.729     |\n",
      "|    explained_variance   | 0.77       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0737    |\n",
      "|    n_updates            | 3570       |\n",
      "|    policy_gradient_loss | -0.0439    |\n",
      "|    value_loss           | 0.0151     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058085095 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0954     |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 836        |\n",
      "|    total_timesteps      | 235520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07389484 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.427     |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0842    |\n",
      "|    n_updates            | 3590       |\n",
      "|    policy_gradient_loss | -0.0433    |\n",
      "|    value_loss           | 0.0599     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 116        |\n",
      "|    time_elapsed         | 842        |\n",
      "|    total_timesteps      | 237568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09019846 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.528     |\n",
      "|    explained_variance   | 0.541      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0829    |\n",
      "|    n_updates            | 3600       |\n",
      "|    policy_gradient_loss | -0.0406    |\n",
      "|    value_loss           | 0.0194     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 117        |\n",
      "|    time_elapsed         | 850        |\n",
      "|    total_timesteps      | 239616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05676759 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.746     |\n",
      "|    explained_variance   | 0.36       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0729    |\n",
      "|    n_updates            | 3610       |\n",
      "|    policy_gradient_loss | -0.0469    |\n",
      "|    value_loss           | 0.0146     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 856         |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.074061036 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0777     |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 0.014       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 119        |\n",
      "|    time_elapsed         | 865        |\n",
      "|    total_timesteps      | 243712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05034137 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.906     |\n",
      "|    explained_variance   | 0.724      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0246    |\n",
      "|    n_updates            | 3630       |\n",
      "|    policy_gradient_loss | -0.0305    |\n",
      "|    value_loss           | 0.0159     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 873         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050779894 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.754      |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.077      |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 0.0195      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 881        |\n",
      "|    total_timesteps      | 247808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11011386 |\n",
      "|    clip_fraction        | 0.373      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.626     |\n",
      "|    explained_variance   | 0.584      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0888    |\n",
      "|    n_updates            | 3650       |\n",
      "|    policy_gradient_loss | -0.0493    |\n",
      "|    value_loss           | 0.016      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 888        |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07789918 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.614     |\n",
      "|    explained_variance   | 0.59       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0781    |\n",
      "|    n_updates            | 3660       |\n",
      "|    policy_gradient_loss | -0.0469    |\n",
      "|    value_loss           | 0.0189     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 896         |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.071884364 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0721     |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.0509     |\n",
      "|    value_loss           | 0.0182      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 904        |\n",
      "|    total_timesteps      | 253952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07248557 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.607     |\n",
      "|    explained_variance   | 0.713      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0775    |\n",
      "|    n_updates            | 3680       |\n",
      "|    policy_gradient_loss | -0.0458    |\n",
      "|    value_loss           | 0.0119     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 912        |\n",
      "|    total_timesteps      | 256000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05648303 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.789     |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0447    |\n",
      "|    n_updates            | 3690       |\n",
      "|    policy_gradient_loss | -0.0371    |\n",
      "|    value_loss           | 0.00827    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 919        |\n",
      "|    total_timesteps      | 258048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06354707 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.707     |\n",
      "|    explained_variance   | 0.624      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0866    |\n",
      "|    n_updates            | 3700       |\n",
      "|    policy_gradient_loss | -0.0482    |\n",
      "|    value_loss           | 0.0204     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 127        |\n",
      "|    time_elapsed         | 927        |\n",
      "|    total_timesteps      | 260096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08117424 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.674     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.08      |\n",
      "|    n_updates            | 3710       |\n",
      "|    policy_gradient_loss | -0.044     |\n",
      "|    value_loss           | 0.0183     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 280       |\n",
      "|    iterations           | 128       |\n",
      "|    time_elapsed         | 934       |\n",
      "|    total_timesteps      | 262144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0806346 |\n",
      "|    clip_fraction        | 0.354     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.6      |\n",
      "|    explained_variance   | 0.686     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0836   |\n",
      "|    n_updates            | 3720      |\n",
      "|    policy_gradient_loss | -0.0574   |\n",
      "|    value_loss           | 0.0136    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 946        |\n",
      "|    total_timesteps      | 264192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08322415 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.681     |\n",
      "|    explained_variance   | 0.776      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 3730       |\n",
      "|    policy_gradient_loss | -0.0385    |\n",
      "|    value_loss           | 0.00995    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 130        |\n",
      "|    time_elapsed         | 953        |\n",
      "|    total_timesteps      | 266240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07536685 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.601     |\n",
      "|    explained_variance   | 0.735      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0115     |\n",
      "|    n_updates            | 3740       |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    value_loss           | 0.0133     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 961         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047904246 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.77       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.052      |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 0.01        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 132        |\n",
      "|    time_elapsed         | 970        |\n",
      "|    total_timesteps      | 270336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08375648 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.701     |\n",
      "|    explained_variance   | 0.73       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0857    |\n",
      "|    n_updates            | 3760       |\n",
      "|    policy_gradient_loss | -0.056     |\n",
      "|    value_loss           | 0.0149     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 277       |\n",
      "|    iterations           | 133       |\n",
      "|    time_elapsed         | 979       |\n",
      "|    total_timesteps      | 272384    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0973976 |\n",
      "|    clip_fraction        | 0.35      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.579    |\n",
      "|    explained_variance   | 0.508     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0709   |\n",
      "|    n_updates            | 3770      |\n",
      "|    policy_gradient_loss | -0.0538   |\n",
      "|    value_loss           | 0.0147    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 134        |\n",
      "|    time_elapsed         | 987        |\n",
      "|    total_timesteps      | 274432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07367182 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.537     |\n",
      "|    explained_variance   | 0.7        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0552    |\n",
      "|    n_updates            | 3780       |\n",
      "|    policy_gradient_loss | -0.045     |\n",
      "|    value_loss           | 0.00922    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 135        |\n",
      "|    time_elapsed         | 994        |\n",
      "|    total_timesteps      | 276480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05800847 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.587     |\n",
      "|    explained_variance   | 0.596      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0617    |\n",
      "|    n_updates            | 3790       |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.0135     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 1002        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051222343 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0762     |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    value_loss           | 0.00917     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 1010       |\n",
      "|    total_timesteps      | 280576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06979854 |\n",
      "|    clip_fraction        | 0.399      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.776     |\n",
      "|    explained_variance   | 0.683      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0926    |\n",
      "|    n_updates            | 3810       |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    value_loss           | 0.00882    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 1016        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061792605 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.647      |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0675     |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 0.0123      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 1023       |\n",
      "|    total_timesteps      | 284672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07154866 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.669     |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0969    |\n",
      "|    n_updates            | 3830       |\n",
      "|    policy_gradient_loss | -0.0541    |\n",
      "|    value_loss           | 0.0134     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 140        |\n",
      "|    time_elapsed         | 1029       |\n",
      "|    total_timesteps      | 286720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07409585 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.606     |\n",
      "|    explained_variance   | 0.623      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0791    |\n",
      "|    n_updates            | 3840       |\n",
      "|    policy_gradient_loss | -0.0503    |\n",
      "|    value_loss           | 0.014      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 1038        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055924326 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.772      |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0882     |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 0.00923     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 142        |\n",
      "|    time_elapsed         | 1046       |\n",
      "|    total_timesteps      | 290816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06751537 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.69      |\n",
      "|    explained_variance   | 0.574      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0983    |\n",
      "|    n_updates            | 3860       |\n",
      "|    policy_gradient_loss | -0.052     |\n",
      "|    value_loss           | 0.0156     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 277       |\n",
      "|    iterations           | 143       |\n",
      "|    time_elapsed         | 1053      |\n",
      "|    total_timesteps      | 292864    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1101544 |\n",
      "|    clip_fraction        | 0.336     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.52     |\n",
      "|    explained_variance   | 0.761     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0781   |\n",
      "|    n_updates            | 3870      |\n",
      "|    policy_gradient_loss | -0.0475   |\n",
      "|    value_loss           | 0.0101    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 1060        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061585527 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0974     |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 0.0115      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 145        |\n",
      "|    time_elapsed         | 1068       |\n",
      "|    total_timesteps      | 296960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06362514 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.662     |\n",
      "|    explained_variance   | 0.711      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0591    |\n",
      "|    n_updates            | 3890       |\n",
      "|    policy_gradient_loss | -0.048     |\n",
      "|    value_loss           | 0.0203     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 1075        |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056396972 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.705      |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0675     |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 0.0497      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 1081        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.076041654 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.655      |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0857     |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | -0.0535     |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 1088       |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05626205 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.784     |\n",
      "|    explained_variance   | 0.825      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0939    |\n",
      "|    n_updates            | 3920       |\n",
      "|    policy_gradient_loss | -0.0435    |\n",
      "|    value_loss           | 0.0111     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 278       |\n",
      "|    iterations           | 149       |\n",
      "|    time_elapsed         | 1096      |\n",
      "|    total_timesteps      | 305152    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0898953 |\n",
      "|    clip_fraction        | 0.356     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.721    |\n",
      "|    explained_variance   | 0.634     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0843   |\n",
      "|    n_updates            | 3930      |\n",
      "|    policy_gradient_loss | -0.043    |\n",
      "|    value_loss           | 0.0169    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 150        |\n",
      "|    time_elapsed         | 1103       |\n",
      "|    total_timesteps      | 307200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08123016 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.613     |\n",
      "|    explained_variance   | 0.754      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0806    |\n",
      "|    n_updates            | 3940       |\n",
      "|    policy_gradient_loss | -0.0617    |\n",
      "|    value_loss           | 0.0129     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 1110       |\n",
      "|    total_timesteps      | 309248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09661156 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.595     |\n",
      "|    explained_variance   | 0.811      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.215      |\n",
      "|    n_updates            | 3950       |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    value_loss           | 0.00702    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 1121       |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07156737 |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.715      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.108     |\n",
      "|    n_updates            | 3960       |\n",
      "|    policy_gradient_loss | -0.0518    |\n",
      "|    value_loss           | 0.0105     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 153        |\n",
      "|    time_elapsed         | 1128       |\n",
      "|    total_timesteps      | 313344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07849618 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.783     |\n",
      "|    explained_variance   | 0.838      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0802    |\n",
      "|    n_updates            | 3970       |\n",
      "|    policy_gradient_loss | -0.0083    |\n",
      "|    value_loss           | 0.00756    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 154        |\n",
      "|    time_elapsed         | 1135       |\n",
      "|    total_timesteps      | 315392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08386795 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.642     |\n",
      "|    explained_variance   | 0.891      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0586    |\n",
      "|    n_updates            | 3980       |\n",
      "|    policy_gradient_loss | -0.0376    |\n",
      "|    value_loss           | 0.00959    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 155        |\n",
      "|    time_elapsed         | 1143       |\n",
      "|    total_timesteps      | 317440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07170612 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.721     |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 3990       |\n",
      "|    policy_gradient_loss | -0.0497    |\n",
      "|    value_loss           | 0.00697    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 156        |\n",
      "|    time_elapsed         | 1156       |\n",
      "|    total_timesteps      | 319488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09532343 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.724     |\n",
      "|    explained_variance   | 0.849      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0822    |\n",
      "|    n_updates            | 4000       |\n",
      "|    policy_gradient_loss | -0.0468    |\n",
      "|    value_loss           | 0.0101     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 157        |\n",
      "|    time_elapsed         | 1166       |\n",
      "|    total_timesteps      | 321536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06624684 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.586     |\n",
      "|    explained_variance   | 0.586      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.104     |\n",
      "|    n_updates            | 4010       |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.0134     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 158        |\n",
      "|    time_elapsed         | 1176       |\n",
      "|    total_timesteps      | 323584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05740203 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.72      |\n",
      "|    explained_variance   | 0.556      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0739    |\n",
      "|    n_updates            | 4020       |\n",
      "|    policy_gradient_loss | -0.0397    |\n",
      "|    value_loss           | 0.0183     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 1187        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058743544 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.775      |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0743     |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 0.0152      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 274      |\n",
      "|    iterations           | 160      |\n",
      "|    time_elapsed         | 1194     |\n",
      "|    total_timesteps      | 327680   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.055628 |\n",
      "|    clip_fraction        | 0.279    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.617   |\n",
      "|    explained_variance   | 0.595    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.108   |\n",
      "|    n_updates            | 4040     |\n",
      "|    policy_gradient_loss | -0.0429  |\n",
      "|    value_loss           | 0.0111   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 1201       |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08203697 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.662     |\n",
      "|    explained_variance   | 0.83       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0907    |\n",
      "|    n_updates            | 4050       |\n",
      "|    policy_gradient_loss | -0.0392    |\n",
      "|    value_loss           | 0.01       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 162        |\n",
      "|    time_elapsed         | 1207       |\n",
      "|    total_timesteps      | 331776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06774342 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.69      |\n",
      "|    explained_variance   | 0.756      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0763    |\n",
      "|    n_updates            | 4060       |\n",
      "|    policy_gradient_loss | -0.05      |\n",
      "|    value_loss           | 0.0117     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 163        |\n",
      "|    time_elapsed         | 1213       |\n",
      "|    total_timesteps      | 333824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05801422 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.72      |\n",
      "|    explained_variance   | 0.731      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0774    |\n",
      "|    n_updates            | 4070       |\n",
      "|    policy_gradient_loss | -0.0467    |\n",
      "|    value_loss           | 0.0105     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 1220        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.078665406 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0615     |\n",
      "|    n_updates            | 4080        |\n",
      "|    policy_gradient_loss | -0.0551     |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 1226        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.068264976 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.63       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0971     |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.0548     |\n",
      "|    value_loss           | 0.0131      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 1232        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051938266 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.423      |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0182      |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.00831     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 167        |\n",
      "|    time_elapsed         | 1238       |\n",
      "|    total_timesteps      | 342016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06178453 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.731     |\n",
      "|    explained_variance   | 0.532      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0957    |\n",
      "|    n_updates            | 4110       |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    value_loss           | 0.0358     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 1245        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059464984 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.737      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0495     |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.0482     |\n",
      "|    value_loss           | 0.0164      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 169        |\n",
      "|    time_elapsed         | 1251       |\n",
      "|    total_timesteps      | 346112     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06323704 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.651     |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0672    |\n",
      "|    n_updates            | 4130       |\n",
      "|    policy_gradient_loss | -0.0518    |\n",
      "|    value_loss           | 0.0185     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 1258        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046947874 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0531     |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 0.0154      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 1264        |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060434036 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.681      |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0585     |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    value_loss           | 0.0169      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 172        |\n",
      "|    time_elapsed         | 1273       |\n",
      "|    total_timesteps      | 352256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06802927 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.59      |\n",
      "|    explained_variance   | 0.464      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.082     |\n",
      "|    n_updates            | 4160       |\n",
      "|    policy_gradient_loss | -0.0509    |\n",
      "|    value_loss           | 0.0333     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 1281        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054775912 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.827      |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0848     |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    value_loss           | 0.0136      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 1290        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042338878 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.691      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0642     |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 274       |\n",
      "|    iterations           | 175       |\n",
      "|    time_elapsed         | 1305      |\n",
      "|    total_timesteps      | 358400    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0772597 |\n",
      "|    clip_fraction        | 0.294     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.6      |\n",
      "|    explained_variance   | 0.738     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0892   |\n",
      "|    n_updates            | 4190      |\n",
      "|    policy_gradient_loss | -0.0513   |\n",
      "|    value_loss           | 0.0246    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 1317        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055953722 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0844     |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    value_loss           | 0.02        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 177        |\n",
      "|    time_elapsed         | 1326       |\n",
      "|    total_timesteps      | 362496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21577269 |\n",
      "|    clip_fraction        | 0.379      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.63      |\n",
      "|    explained_variance   | 0.564      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.103     |\n",
      "|    n_updates            | 4210       |\n",
      "|    policy_gradient_loss | -0.0554    |\n",
      "|    value_loss           | 0.0164     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 178        |\n",
      "|    time_elapsed         | 1333       |\n",
      "|    total_timesteps      | 364544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08131545 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.528     |\n",
      "|    explained_variance   | 0.657      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0892    |\n",
      "|    n_updates            | 4220       |\n",
      "|    policy_gradient_loss | -0.046     |\n",
      "|    value_loss           | 0.0123     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 1341       |\n",
      "|    total_timesteps      | 366592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07689022 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.635     |\n",
      "|    explained_variance   | 0.643      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0857    |\n",
      "|    n_updates            | 4230       |\n",
      "|    policy_gradient_loss | -0.0544    |\n",
      "|    value_loss           | 0.0231     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 1347        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061799727 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.65       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0781     |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.0516     |\n",
      "|    value_loss           | 0.0148      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 181        |\n",
      "|    time_elapsed         | 1354       |\n",
      "|    total_timesteps      | 370688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06999214 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.716     |\n",
      "|    explained_variance   | 0.695      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0435     |\n",
      "|    n_updates            | 4250       |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 0.0153     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 182        |\n",
      "|    time_elapsed         | 1361       |\n",
      "|    total_timesteps      | 372736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05313386 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.746     |\n",
      "|    explained_variance   | 0.782      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0531    |\n",
      "|    n_updates            | 4260       |\n",
      "|    policy_gradient_loss | -0.0387    |\n",
      "|    value_loss           | 0.0102     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 183        |\n",
      "|    time_elapsed         | 1367       |\n",
      "|    total_timesteps      | 374784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05512297 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.67      |\n",
      "|    explained_variance   | 0.602      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00448   |\n",
      "|    n_updates            | 4270       |\n",
      "|    policy_gradient_loss | -0.0459    |\n",
      "|    value_loss           | 0.0167     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 1374        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044397518 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0667     |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.00838     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 1381       |\n",
      "|    total_timesteps      | 378880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07595791 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.745     |\n",
      "|    explained_variance   | 0.686      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.056     |\n",
      "|    n_updates            | 4290       |\n",
      "|    policy_gradient_loss | -0.0448    |\n",
      "|    value_loss           | 0.0149     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 186        |\n",
      "|    time_elapsed         | 1389       |\n",
      "|    total_timesteps      | 380928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03697478 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.859     |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0475    |\n",
      "|    n_updates            | 4300       |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.00921    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 1399        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055036712 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.796      |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.065      |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 188        |\n",
      "|    time_elapsed         | 1406       |\n",
      "|    total_timesteps      | 385024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08419196 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.57      |\n",
      "|    explained_variance   | 0.614      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0822    |\n",
      "|    n_updates            | 4320       |\n",
      "|    policy_gradient_loss | -0.0521    |\n",
      "|    value_loss           | 0.019      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 189        |\n",
      "|    time_elapsed         | 1412       |\n",
      "|    total_timesteps      | 387072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08815644 |\n",
      "|    clip_fraction        | 0.444      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.784     |\n",
      "|    explained_variance   | 0.472      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.09      |\n",
      "|    n_updates            | 4330       |\n",
      "|    policy_gradient_loss | -0.0518    |\n",
      "|    value_loss           | 0.0134     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 190        |\n",
      "|    time_elapsed         | 1419       |\n",
      "|    total_timesteps      | 389120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09808942 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.611     |\n",
      "|    explained_variance   | 0.652      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0823    |\n",
      "|    n_updates            | 4340       |\n",
      "|    policy_gradient_loss | -0.0456    |\n",
      "|    value_loss           | 0.0106     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 1426        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062812395 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0885     |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 0.00829     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 1442        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034900475 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.986      |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0252     |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.0116      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 1449        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061190322 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.823      |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0646     |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 0.00954     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 194        |\n",
      "|    time_elapsed         | 1456       |\n",
      "|    total_timesteps      | 397312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07133205 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.692     |\n",
      "|    explained_variance   | 0.61       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0689    |\n",
      "|    n_updates            | 4380       |\n",
      "|    policy_gradient_loss | -0.0463    |\n",
      "|    value_loss           | 0.00867    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 195        |\n",
      "|    time_elapsed         | 1462       |\n",
      "|    total_timesteps      | 399360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07369113 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.7       |\n",
      "|    explained_variance   | 0.678      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.11      |\n",
      "|    n_updates            | 4390       |\n",
      "|    policy_gradient_loss | -0.0478    |\n",
      "|    value_loss           | 0.0161     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 1468        |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050948754 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.798      |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0823     |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.0495     |\n",
      "|    value_loss           | 0.0119      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 1475        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045276463 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.911      |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0726     |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 0.019       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 198        |\n",
      "|    time_elapsed         | 1481       |\n",
      "|    total_timesteps      | 405504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08166584 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.647     |\n",
      "|    explained_variance   | 0.7        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0311    |\n",
      "|    n_updates            | 4420       |\n",
      "|    policy_gradient_loss | -0.054     |\n",
      "|    value_loss           | 0.0136     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 1487        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054713644 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.779      |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0816     |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 0.0288      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 1493        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061271273 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.745      |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0768     |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.0496      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 201        |\n",
      "|    time_elapsed         | 1499       |\n",
      "|    total_timesteps      | 411648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07368186 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.707     |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0813    |\n",
      "|    n_updates            | 4450       |\n",
      "|    policy_gradient_loss | -0.0506    |\n",
      "|    value_loss           | 0.0217     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 1506        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.066702105 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.644      |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0805     |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.0516     |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 1512        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044928357 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.68       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0596     |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 0.0439      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 1518       |\n",
      "|    total_timesteps      | 417792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16072713 |\n",
      "|    clip_fraction        | 0.414      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.674     |\n",
      "|    explained_variance   | 0.764      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0795    |\n",
      "|    n_updates            | 4480       |\n",
      "|    policy_gradient_loss | -0.0491    |\n",
      "|    value_loss           | 0.0241     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 205        |\n",
      "|    time_elapsed         | 1525       |\n",
      "|    total_timesteps      | 419840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07617141 |\n",
      "|    clip_fraction        | 0.345      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.639     |\n",
      "|    explained_variance   | 0.553      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0427    |\n",
      "|    n_updates            | 4490       |\n",
      "|    policy_gradient_loss | -0.0491    |\n",
      "|    value_loss           | 0.0185     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 1533        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.083080396 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0742     |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.0504     |\n",
      "|    value_loss           | 0.0179      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 207        |\n",
      "|    time_elapsed         | 1539       |\n",
      "|    total_timesteps      | 423936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06395205 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.601     |\n",
      "|    explained_variance   | 0.497      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0787    |\n",
      "|    n_updates            | 4510       |\n",
      "|    policy_gradient_loss | -0.054     |\n",
      "|    value_loss           | 0.0199     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 1545        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054498203 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.103      |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | -0.0483     |\n",
      "|    value_loss           | 0.0138      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 1551       |\n",
      "|    total_timesteps      | 428032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07548353 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.703     |\n",
      "|    explained_variance   | 0.515      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0754    |\n",
      "|    n_updates            | 4530       |\n",
      "|    policy_gradient_loss | -0.0538    |\n",
      "|    value_loss           | 0.0143     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 1557        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057413183 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.729      |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0816     |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.0488     |\n",
      "|    value_loss           | 0.0158      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 211        |\n",
      "|    time_elapsed         | 1564       |\n",
      "|    total_timesteps      | 432128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08002815 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.648     |\n",
      "|    explained_variance   | 0.434      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0841    |\n",
      "|    n_updates            | 4550       |\n",
      "|    policy_gradient_loss | -0.0523    |\n",
      "|    value_loss           | 0.0139     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 212        |\n",
      "|    time_elapsed         | 1570       |\n",
      "|    total_timesteps      | 434176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07118338 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.82      |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0752    |\n",
      "|    n_updates            | 4560       |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    value_loss           | 0.0102     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 213        |\n",
      "|    time_elapsed         | 1576       |\n",
      "|    total_timesteps      | 436224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06340858 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.814     |\n",
      "|    explained_variance   | 0.823      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.012     |\n",
      "|    n_updates            | 4570       |\n",
      "|    policy_gradient_loss | -0.0474    |\n",
      "|    value_loss           | 0.0116     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 214        |\n",
      "|    time_elapsed         | 1583       |\n",
      "|    total_timesteps      | 438272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06127597 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.762     |\n",
      "|    explained_variance   | 0.793      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 4580       |\n",
      "|    policy_gradient_loss | -0.0479    |\n",
      "|    value_loss           | 0.00964    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 1589        |\n",
      "|    total_timesteps      | 440320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.078626946 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.721      |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0966     |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.0529     |\n",
      "|    value_loss           | 0.016       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 1597       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06596659 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.809     |\n",
      "|    explained_variance   | 0.741      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0739    |\n",
      "|    n_updates            | 4600       |\n",
      "|    policy_gradient_loss | -0.0475    |\n",
      "|    value_loss           | 0.0147     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 1603        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.090987585 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.654      |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0824     |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 0.0097      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 1609        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070689574 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.635      |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.121      |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.0552     |\n",
      "|    value_loss           | 0.0134      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 219        |\n",
      "|    time_elapsed         | 1615       |\n",
      "|    total_timesteps      | 448512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09125967 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.72      |\n",
      "|    explained_variance   | 0.67       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0842    |\n",
      "|    n_updates            | 4630       |\n",
      "|    policy_gradient_loss | -0.0489    |\n",
      "|    value_loss           | 0.0136     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 1622        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042784642 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.928      |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0535     |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    value_loss           | 0.0135      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 221        |\n",
      "|    time_elapsed         | 1629       |\n",
      "|    total_timesteps      | 452608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06972345 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.661     |\n",
      "|    explained_variance   | 0.752      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0931    |\n",
      "|    n_updates            | 4650       |\n",
      "|    policy_gradient_loss | -0.0476    |\n",
      "|    value_loss           | 0.0114     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 222        |\n",
      "|    time_elapsed         | 1635       |\n",
      "|    total_timesteps      | 454656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06056217 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.782     |\n",
      "|    explained_variance   | 0.787      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0616    |\n",
      "|    n_updates            | 4660       |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    value_loss           | 0.0124     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 1641        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051177315 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.08       |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    value_loss           | 0.0113      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 1647        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043862704 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0782     |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 0.0129      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 225        |\n",
      "|    time_elapsed         | 1655       |\n",
      "|    total_timesteps      | 460800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09239994 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.733     |\n",
      "|    explained_variance   | 0.651      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0787    |\n",
      "|    n_updates            | 4690       |\n",
      "|    policy_gradient_loss | -0.0535    |\n",
      "|    value_loss           | 0.0151     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 226        |\n",
      "|    time_elapsed         | 1662       |\n",
      "|    total_timesteps      | 462848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08061862 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.682     |\n",
      "|    explained_variance   | 0.61       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0578    |\n",
      "|    n_updates            | 4700       |\n",
      "|    policy_gradient_loss | -0.0352    |\n",
      "|    value_loss           | 0.0131     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 227        |\n",
      "|    time_elapsed         | 1668       |\n",
      "|    total_timesteps      | 464896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06984383 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.744     |\n",
      "|    explained_variance   | 0.692      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0716    |\n",
      "|    n_updates            | 4710       |\n",
      "|    policy_gradient_loss | -0.046     |\n",
      "|    value_loss           | 0.0154     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 1674        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.066252686 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0677     |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 0.00953     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 229        |\n",
      "|    time_elapsed         | 1681       |\n",
      "|    total_timesteps      | 468992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08610156 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.651     |\n",
      "|    explained_variance   | 0.809      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0769    |\n",
      "|    n_updates            | 4730       |\n",
      "|    policy_gradient_loss | -0.0551    |\n",
      "|    value_loss           | 0.0112     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 1687        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053947493 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0817     |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 1694        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.071428865 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.624      |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0779     |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.0488     |\n",
      "|    value_loss           | 0.0118      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 232        |\n",
      "|    time_elapsed         | 1700       |\n",
      "|    total_timesteps      | 475136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15036452 |\n",
      "|    clip_fraction        | 0.481      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.78      |\n",
      "|    explained_variance   | 0.566      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.108     |\n",
      "|    n_updates            | 4760       |\n",
      "|    policy_gradient_loss | -0.0744    |\n",
      "|    value_loss           | 0.0141     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 233        |\n",
      "|    time_elapsed         | 1706       |\n",
      "|    total_timesteps      | 477184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07946776 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.55      |\n",
      "|    explained_variance   | 0.707      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0896    |\n",
      "|    n_updates            | 4770       |\n",
      "|    policy_gradient_loss | -0.0446    |\n",
      "|    value_loss           | 0.0194     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 1713        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049440674 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.759      |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0862     |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.0127      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 1720        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028568927 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.67       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0517     |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.0197      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 236        |\n",
      "|    time_elapsed         | 1726       |\n",
      "|    total_timesteps      | 483328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07386553 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.715     |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0599    |\n",
      "|    n_updates            | 4800       |\n",
      "|    policy_gradient_loss | -0.026     |\n",
      "|    value_loss           | 0.00925    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 1732        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.074406125 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.0777      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0614     |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    value_loss           | 0.00964     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 238        |\n",
      "|    time_elapsed         | 1739       |\n",
      "|    total_timesteps      | 487424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06680639 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.668     |\n",
      "|    explained_variance   | 0.769      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0596    |\n",
      "|    n_updates            | 4820       |\n",
      "|    policy_gradient_loss | -0.0292    |\n",
      "|    value_loss           | 0.0109     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 1746        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059935268 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0616     |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 0.00926     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 1752        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.092749335 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.726      |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0858     |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 0.00843     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 241        |\n",
      "|    time_elapsed         | 1758       |\n",
      "|    total_timesteps      | 493568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07617822 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.63      |\n",
      "|    explained_variance   | 0.661      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0738    |\n",
      "|    n_updates            | 4850       |\n",
      "|    policy_gradient_loss | -0.0439    |\n",
      "|    value_loss           | 0.0122     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 242        |\n",
      "|    time_elapsed         | 1764       |\n",
      "|    total_timesteps      | 495616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08915364 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.578     |\n",
      "|    explained_variance   | 0.672      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0706    |\n",
      "|    n_updates            | 4860       |\n",
      "|    policy_gradient_loss | -0.05      |\n",
      "|    value_loss           | 0.0145     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 243        |\n",
      "|    time_elapsed         | 1771       |\n",
      "|    total_timesteps      | 497664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06265275 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.694     |\n",
      "|    explained_variance   | 0.655      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0991    |\n",
      "|    n_updates            | 4870       |\n",
      "|    policy_gradient_loss | -0.0424    |\n",
      "|    value_loss           | 0.0147     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 1778        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057647035 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0547     |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 0.0104      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 245        |\n",
      "|    time_elapsed         | 1785       |\n",
      "|    total_timesteps      | 501760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08614692 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.641     |\n",
      "|    explained_variance   | 0.791      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0797    |\n",
      "|    n_updates            | 4890       |\n",
      "|    policy_gradient_loss | -0.0503    |\n",
      "|    value_loss           | 0.0109     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1ecf218b750>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPO_DRL_model.learn(total_timesteps=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dd6b4",
   "metadata": {},
   "source": [
    "## Save PPO DRL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed16e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Model_Custom = os.path.join('Training_Star_Wars_Galaxy_Phase_2', 'Saved RL Models', 'PPO_Model_Star_Wars_Galaxy_1M')\n",
    "PPO_DRL_model.save(PPO_Model_Custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce62ff80",
   "metadata": {},
   "source": [
    "## Reload PPO DRL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a3a67ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "PPO_Model_Custom = os.path.join('Training_Star_Wars_Galaxy_Phase_2', 'Saved RL Models', 'PPO_Model_Star_Wars_Galaxy_1M')\n",
    "reloaded_PPO_DRL_model = PPO.load(PPO_Model_Custom, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c305f3",
   "metadata": {},
   "source": [
    "## Test the PPO DRL model in a RL Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5562c2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 | Score: -862.84 | Planets Found: 19/20 | Damages: 72\n",
      "Episode: 2 | Score: 778.50 | Planets Found: 11/20 | Damages: 5\n",
      "Episode: 3 | Score: 520.85 | Planets Found: 19/20 | Damages: 34\n",
      "Episode: 4 | Score: 60.21 | Planets Found: 20/20 | Damages: 54\n",
      "Episode: 5 | Score: -1400.72 | Planets Found: 20/20 | Damages: 152\n",
      "\n",
      "Average planets found over 5 episodes: 17.80\n"
     ]
    }
   ],
   "source": [
    "env = OuterRimEnv(5,5)\n",
    "\n",
    "episodes = 5\n",
    "total_planets_found = 0\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    # Initialise starting state of the RL agent in the RL Environment before an episode, done to false, and starting \n",
    "    # episode score to 0\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    episode_score = 0\n",
    "\n",
    "    # During an episode:\n",
    "    while not done:\n",
    "        env.render()\n",
    "        # RL agent determines action to take\n",
    "        # - Now, we are no longer randomly sampling an action to take by our RL agent in the RL Environment, but\n",
    "        #   instead we are using the PPO DRL model to predict the action at each time step in an episode instead based\n",
    "        #   on the current observations/states in the RL Environment\n",
    "        action, _ = reloaded_PPO_DRL_model.predict(obs)\n",
    "        # RL Environment generates the next state and reward gained upon taking the action in the current state\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        # Append the reward gained upon taking the action in the current state to the cumulative episode date\n",
    "        episode_score += reward\n",
    "\n",
    "    total_planets_found += info['visited_planets']\n",
    "    print(f\"Episode: {episode} | Score: {episode_score:.2f} | Planets Found: {info['visited_planets']}/{info['total_planets']} | Damages: {info['damages']}\")\n",
    "    \n",
    "env.close()\n",
    "\n",
    "average_planets_found = total_planets_found / episodes\n",
    "print(f\"\\nAverage planets found over {episodes} episodes: {average_planets_found:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
