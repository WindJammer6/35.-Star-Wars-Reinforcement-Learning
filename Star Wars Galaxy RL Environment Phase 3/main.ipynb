{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58ce506",
   "metadata": {},
   "source": [
    "# Star Wars Galaxy Explorers (Phase 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c592e",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    text-align: center;\n",
    "    font-family: Arial, sans-serif;\n",
    "    color: yellow;\n",
    "    background: black;\n",
    "    padding: 20px;\n",
    "\">\n",
    "    <p style=\"font-size: 16px; margin: 10px 0;\">Turns out, some of the planets are</p>\n",
    "    <p style=\"font-size: 20px; margin: 10px 0;\">hostile to outsiders due to the fear of being</p>\n",
    "    <p style=\"font-size: 24px; margin: 10px 0;\">conquered by either side of the war. They will</p>\n",
    "    <p style=\"font-size: 28px; margin: 10px 0;\">destroy any ship entering their sector. The drones'</p>\n",
    "    <p style=\"font-size: 32px; margin: 10px 0;\">destroyed locations are known to the hive mind, which is</p>\n",
    "    <p style=\"font-size: 36px; margin: 10px 0;\">then updated to future future drones to help them in their</p>\n",
    "    <p style=\"font-size: 40px; margin: 10px 0;\">expedition to help with identifying and avoiding such</p>\n",
    "    <p style=\"font-size: 44px; margin: 10px 0;\">planets.</p>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1ff95",
   "metadata": {},
   "source": [
    "## Build Outer Rim POMDP (Partially Observable Markov Decision Process) RL Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f41d4f",
   "metadata": {},
   "source": [
    "### What is the MDP components of the Outer Rim POMDP RL Environment?\n",
    "\n",
    "**1. (Reality) State Space**\n",
    "- all actual states of the Outer Rim POMDP RL Environment\n",
    "\n",
    "| **Component**                       | **Type / Description**                             | **Purpose**                                                                         |\n",
    "| ----------------------------------- | -------------------------------------------------- | ----------------------------------------------------------------------------------- |\n",
    "| `map`                               | 2D grid consisting of different objects, denoted by characters (`' '`, `'#'`, `'.'`, `'S'`), where ' ' is empty space, '#' is a planet, '.' is a visited planet, 'S' is the starting position that the agent can see and remember | Represents environment layout and object locations (empty, planets, visited planets, start positions) |\n",
    "| `state`                             | Tuple `(row, col)`                                 | Current agent location                                                              |\n",
    "| `vision_radius`                     | 2D binary matrix                                   | Tracks all cells the agent has can see at a time, serves as the agent's 'vision'                                            |\n",
    "| `seen_map`                          | 2D binary matrix                                   | Tracks all cells the agent has ever seen, serves as the agent's 'memory'                                            |\n",
    "| `mission_time_before_self_destruct` | Integer countdown                                  | Terminates mission/episode when time runs out                                               |\n",
    "| `planet_reward_map`                 | 2D float matrix                                    | Used to map the dense reward field (halo) from discovered planets                                   |\n",
    "| `discovered_planet`                 | Set of coordinates                                 | Used to track which planets were already visited                                           |\n",
    "| `npc_list`                          | List of enemy/friendly ships with position/state   | Governs danger field and combat logic                                               |\n",
    "| `agent_damage_taken`                | Boolean flag / counter                             | Used to track if agent was damaged by a 'SeparatistShip'                                                        |\n",
    "| `death_halo_map`                    | 2D float matrix (negative)                         | Propagates danger field from prior agents deaths between sub-episodes in a outer episode                                           |\n",
    "| `hive_memory`                       | 2D binary matrix                                   | Shared binary memory across agents between sub-episodes in a outer episode                                                  |\n",
    "| `hostile_planets`                   | Set of positions with kill-radius                  | Hostile death zones from which agents die instantly and the sub-episode is terminated                                 |\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. (Agent's) Observation Space**\n",
    "- all observable states by the agent in the Outer Rim POMDP RL Environment\n",
    "\n",
    "| **Component**                    | **Type / Description**                                 | **Purpose**                                                                         |\n",
    "| -------------------------------- | ------------------------------------------------ | ----------------------------------------------------------------------------------- |\n",
    "| `vision_radius`                     | 2D binary matrix                                   | Tracks all cells the agent has can see at a time, serves as the agent's 'vision'                                            |\n",
    "| `seen_memory` / `reward_memory`                          | 2D binary matrix                                   | Tracks all cells the agent has ever seen, serves as the agent's 'memory' or rewarding areas                                           |\n",
    "| `danger`                         | 2D float matrix (same shape as vision)           | Local perception of enemy threat level                                              |\n",
    "| `hive_memory`                    | 2D binary matrix (same shape as vision)          | Local window of the shared hive mind memory between sub-episodes in a outer episode                                        |\n",
    "\n",
    "<br>\n",
    "\n",
    "**3. Action Space**\n",
    "- denoted by the type: Discrete(4)\n",
    "\n",
    "| **Index** | **Action Name** | **Meaning**         |\n",
    "| --------- | --------------- | ------------------- |\n",
    "| 0         | Forward         | Forward by 1 pixel  |\n",
    "| 1         | Backward        | Backward by 1 pixel |\n",
    "| 2         | Leftward        | Leftward by 1 pixel |\n",
    "| 3         | Rightward       | Rightward by 1 pixel |\n",
    "\n",
    "<br>\n",
    "\n",
    "**4. Transition Probability**  \n",
    "- Deterministic\n",
    "\n",
    "<br>\n",
    "\n",
    "**5. Reward Function**  \n",
    "- see the 'Calculate Reward with Reward Function' section in the 'step()' function below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55849ac7",
   "metadata": {},
   "source": [
    "## More about the Hostile Planets\n",
    "Initially the RL agent dosent know it is hostile and is attracted to it by its positive reward halo and the RL agent will get killed. For the sake of hastening training, once a RL agent gets killed by a particular hostile planet, we assume it knows which hostile planet killed it and uploads this memory to the hive mind. The positive reward halo around it is removed after (so its basically a visited planet now, which has a slight negative reward halo, discouraging future RL agents from visiting that hostile planet)\n",
    "\n",
    "I noticed this was an issue when the RL agents, despite giving them a negative reward death halo at the death locations of previous RL agents, they keep 'suiciding' at the same hostile planet. Thats when I realised its because I forgot to remove their positive rewards halo, which was attracting the RL agents, and is never removed since these hostile planets never get visited (since it kills any RL agent entering its radius before they can reach the hostile planet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4197cd01",
   "metadata": {},
   "source": [
    "## More about the Hive Mind feature\n",
    "Future drone expeditions can see where previous drones died, and are discouraged from going there (since the hostile planets are there and shot down previous drones). They can also see previous drones' explored areas. Essentially, the 'seen_memory' of previous drones are uploaded into future drones to help them find planets and avoid hostile planets.\n",
    "\n",
    "Visited planets by previous expeditions stays visited in future expeditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gymnasium-related dependencies\n",
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "# Import Stable Baselines3-related dependencies\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "\n",
    "# Import pygame-related dependencies\n",
    "import pygame\n",
    "\n",
    "# Import helper dependencies\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import local classes\n",
    "from entity_manager import EntityManager\n",
    "from npc_ships import SeperatistShip, RepublicShip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuterRimEnv(Env):\n",
    "    def __init__(self, n_sep, n_rep):\n",
    "        # --- related to world's state spaces --------------------------------------------------------\n",
    "        self.map = self.generate_map()\n",
    "        self.num_rows, self.num_cols = self.map.shape\n",
    "        self.start_position = tuple(np.argwhere(self.map == 'S')[0])\n",
    "        self.state = self.start_position        # Initialising the initial state of the RL Environment\n",
    "        self.n_sep = n_sep                      # number of separatist ships\n",
    "        self.n_rep = n_rep                      # number of republic ships\n",
    "\n",
    "        # --- related to RL agent, observation spaces and action spaces ----------------------------------------------------\n",
    "        self.action_space = Discrete(4)\n",
    "\n",
    "        # Giving the RL agent, 'vision' around it\n",
    "        # Vision radius: e.g. 1 → 3x3 grid (center + 1 square in each direction)\n",
    "        self.vision_radius = 7\n",
    "        obs_height = obs_width = 2 * self.vision_radius + 1\n",
    "        self.hive_memory = np.zeros((self.num_rows, self.num_cols), dtype=bool)\n",
    "\n",
    "        self.living_penalty = 0.03  # tiny cost per step to discourage camping\n",
    "\n",
    "        # Each cell is one of: empty space (' '), planet ('#'), visited planet ('.'), start ('S'), RepublicShip ('R')\n",
    "        # Map characters as integers → you can define a vocab for it\n",
    "        self.char_to_int = {' ': 0, '#': 1, '.': 2, 'S': 3, 'R': 4}\n",
    "\n",
    "        # Observation: local grid (3x3) with integer values, plus mission time\n",
    "        self.observation_space = Dict({\n",
    "            \"vision\"       : Box(low=0,   high=4,         shape=(obs_height, obs_width), dtype=np.uint8),\n",
    "            \"danger\"       : Box(low=0.0, high=1.0,       shape=(obs_height, obs_width), dtype=np.float32),\n",
    "            \"reward_memory\": Box(low=0.0, high=np.inf,    shape=(obs_height, obs_width), dtype=np.float32),\n",
    "            \"hive_memory\": Box(low=0.0, high=1.0, shape=(obs_height, obs_width), dtype=np.float32)\n",
    "        })\n",
    "        \n",
    "\n",
    "        #  --- mission state -----------------------------------------------\n",
    "        self.mission_time_before_self_destruct = 300\n",
    "\n",
    "        # To be used in reward function to give the RL agent a reward for seeing an unexplored pixel\n",
    "        # for the first time. Creating a copy of the map to mark regions that are seen or not.\n",
    "        self.seen_map = np.zeros((self.num_rows, self.num_cols), dtype=bool)\n",
    "        self.agent_damage_taken = False\n",
    "        self.agent_destroyed = False\n",
    "        self.damages = 0  # counts number of times agent has been damaged\n",
    "\n",
    "\n",
    "        # --- entities -----------------------------------------------------\n",
    "        self.entities = []               # list of ALL MobileEntity\n",
    "        self.agent = self                # optional alias if you treat env as agent wrapper\n",
    "        self.entity_mgr = EntityManager(self, n_rep=self.n_rep, n_sep=self.n_sep)     # define number of 'SeparatistShips' and 'RepublicShips' being created\n",
    "        \n",
    "        self.hostile_planet_map = np.zeros((self.num_rows, self.num_cols), dtype=bool)\n",
    "        self.deaths = 0\n",
    "\n",
    "\n",
    "        # --- persistent maps -------------------------------------------------\n",
    "        self.discovered_planet = np.zeros((self.num_rows, self.num_cols), dtype=bool)\n",
    "        self.planet_reward_map = np.zeros((self.num_rows, self.num_cols), dtype=np.float32)\n",
    "\n",
    "        # tunables\n",
    "        self.planet_reward_scale = 2.0     # reward at the planet tile itself\n",
    "        self.planet_reward_decay = 3.0     # larger → slower fall-off\n",
    "\n",
    "\n",
    "        # --- related to hostile planets ---------------------------------------\n",
    "        self.hostile_kill_radius = 2\n",
    "\n",
    "        self.hostile_frac     = 0.10\n",
    "        planet_cells = [(r, c) for r, c in zip(*np.where(self.map == '#'))]\n",
    "        n_hostile    = int(len(planet_cells) * self.hostile_frac)               # (e.g. 20% of all planets)\n",
    "        self.hostile = set(random.sample(planet_cells, n_hostile))\n",
    "\n",
    "        self.death_halo_map = np.zeros((self.num_rows, self.num_cols), np.float32)  # persistent memory across sub-episodes\n",
    "\n",
    "        self.death_halo_scale  = 8\n",
    "        self.death_halo_decay  = 0.8\n",
    "\n",
    "        self.death_locations: list[tuple[int,int]] = [] \n",
    "\n",
    "        self.known_hostile = set()     # planets whose danger is already in the hive\n",
    "\n",
    "\n",
    "        # --- pygame -----------------------------------------------\n",
    "        pygame.init()\n",
    "        self.cell_size = 20  # reduce cell size to fit 40x40 on screen\n",
    "        self.screen = pygame.display.set_mode(\n",
    "            (self.num_cols * self.cell_size, self.num_rows * self.cell_size)\n",
    "        )\n",
    "        pygame.display.set_caption(\"Star Wars Galaxy Explorer (Phase 3)\")\n",
    "\n",
    "\n",
    "    ####################\n",
    "    # Helper functions #\n",
    "    ####################\n",
    "    def generate_map(self, rows=40, cols=40, num_planets=20):\n",
    "        map = np.full((rows, cols), \" \", dtype='<U1')\n",
    "\n",
    "        # Randomly choose N planet positions (excluding start) and keeping the number of planets in each\n",
    "        # episode constant\n",
    "        available_positions = [(i, j) for i in range(rows) for j in range(cols) if (i, j) != (39, 21)]\n",
    "        planet_positions = random.sample(available_positions, num_planets)\n",
    "\n",
    "        for i, j in planet_positions:\n",
    "            map[i, j] = '#'\n",
    "\n",
    "        map[39, 21] = 'S'\n",
    "        return map\n",
    "\n",
    "    def get_RL_agent_local_observation(self):\n",
    "        r, c = self.state\n",
    "        v = self.vision_radius\n",
    "        size = 2*v + 1\n",
    "\n",
    "        obs = np.zeros((size, size), dtype=np.uint8)\n",
    "        rm  = np.zeros_like(obs, dtype=np.float32)\n",
    "        dang = np.zeros_like(obs, dtype=np.float32)\n",
    "\n",
    "        # a. vision -------------------------------\n",
    "        for dr in range(-v, v + 1):\n",
    "            for dc in range(-v, v + 1):\n",
    "                rr, cc = r + dr, c + dc\n",
    "                if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                    cell_char = self.map[rr, cc]\n",
    "                    obs[dr + v, dc + v] = self.char_to_int.get(cell_char, 0)\n",
    "                else:\n",
    "                    obs[dr + v, dc + v] = 0\n",
    "\n",
    "        # b. transient danger map  -------------------------------------\n",
    "        for ship in self.entities:\n",
    "            if not isinstance(ship, SeperatistShip):\n",
    "                continue\n",
    "            sr, sc = ship.pos\n",
    "            # relative position of the ship w.r.t agent\n",
    "            rel_r, rel_c = sr - r + v, sc - c + v\n",
    "            if not (0 <= rel_r < size and 0 <= rel_c < size):\n",
    "                continue           # ship is outside vision → no penalty\n",
    "\n",
    "            for dr in range(-v, v + 1):\n",
    "                for dc in range(-v, v + 1):\n",
    "                    dist = abs(dr) + abs(dc)          # Manhattan distance\n",
    "                    if dist > v:                      # outside view\n",
    "                        continue\n",
    "                    # heavier penalty near the ship, linearly decaying\n",
    "                    penalty = (v - dist + 1) / (v + 1)    # 1.0 at dis = 0 → ≈ 0.09 at edge\n",
    "                    cell_r, cell_c = rel_r + dr, rel_c + dc\n",
    "                    if 0 <= cell_r < size and 0 <= cell_c < size:\n",
    "                        penalty = (v - dist + 1) / (v + 1)\n",
    "                        dang[cell_r, cell_c] = max(dang[cell_r, cell_c], penalty)\n",
    "\n",
    "        # c. reward memory map -------------------------------\n",
    "        rm  = np.zeros_like(obs, dtype=np.float32)\n",
    "        for dr in range(-v, v + 1):\n",
    "            for dc in range(-v, v + 1):\n",
    "                rr, cc = r + dr, c + dc\n",
    "                if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                    rm[dr+v, dc+v] = self.planet_reward_map[rr, cc]\n",
    "\n",
    "        # d. show RepublicShips  -------------------------------------\n",
    "        for ship in self.entities:\n",
    "            if isinstance(ship, RepublicShip):\n",
    "                sr, sc = ship.pos              # ship row / col on the big map\n",
    "                rel_r, rel_c = sr - r + v, sc - c + v   # coordinates inside vision window\n",
    "                if 0 <= rel_r < size and 0 <= rel_c < size:\n",
    "                    obs[rel_r, rel_c] = self.char_to_int['R']\n",
    "\n",
    "        # e. hive memory (map of known hostile planet deaths) -------------------------------\n",
    "        hive = np.zeros_like(obs, dtype=np.float32)\n",
    "        for dr in range(-v, v+1):\n",
    "            for dc in range(-v, v+1):\n",
    "                rr, cc = r+dr, c+dc\n",
    "                if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                    hive[dr+v, dc+v] = self.hive_memory[rr, cc]\n",
    "\n",
    "        return {\n",
    "            \"vision\": obs,          # Current visual snapshot (local terrain)\n",
    "            \"danger\": dang,          # Danger map \n",
    "            \"reward_memory\": rm,     # Agent's remembered \"explored\" map\n",
    "            \"hive_memory\": hive\n",
    "        }\n",
    "    \n",
    "    def is_fatal(self, pos):\n",
    "        \"\"\"A tile is lethal only if it is inside a hostile-planet kill radius.\"\"\"\n",
    "        r, c = pos\n",
    "        for hr, hc in self.hostile:\n",
    "            if max(abs(r - hr), abs(c - hc)) <= self.hostile_kill_radius:\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    def _inject_death_halo(self, centre):\n",
    "        \"\"\"Add a negative halo around the death spot AND neutralise the culprit\n",
    "       hostile planet if we can identify it.\"\"\"\n",
    "        # a. standard negative halo\n",
    "        self.death_locations.append(centre)\n",
    "        cr, cc = centre\n",
    "        for r in range(self.num_rows):\n",
    "            for c in range(self.num_cols):\n",
    "                d = max(abs(r-cr), abs(c-cc))                  # Chebyshev\n",
    "                if d > self.hostile_kill_radius:               # optional cutoff\n",
    "                    continue\n",
    "                strength = -self.death_halo_scale / (1.0 + self.death_halo_decay*d)\n",
    "                self.death_halo_map[r, c] += strength\n",
    "        \n",
    "        # b. Locate the hostile planet that killed the RL agent\n",
    "        for hr, hc in self.hostile:\n",
    "            if max(abs(cr-hr), abs(cc-hc)) <= self.hostile_kill_radius:\n",
    "                if (hr, hc) not in self.known_hostile:\n",
    "                    # wipe its positive halo\n",
    "                    self._inject_planet_reward((hr, hc), sign=-1.0)\n",
    "\n",
    "                    # OPTIONAL: leave a weak negative halo so drones keep a distance\n",
    "                    self._inject_planet_reward((hr, hc), sign=-0.2)\n",
    "\n",
    "                    # treat map symbol like a visited planet (so it's green in UI)\n",
    "                    self.map[hr, hc] = '.'\n",
    "\n",
    "                    self.known_hostile.add((hr, hc))\n",
    "                break          # only one planet can be responsible\n",
    "            \n",
    "        \n",
    "    def _inject_planet_reward(self, pos, sign=+1.0):\n",
    "        \"\"\"Add (+1) or remove (−1) this planet’s contribution from planet_reward_map.\"\"\"\n",
    "        pr, pc = pos\n",
    "        for r in range(self.num_rows):\n",
    "            for c in range(self.num_cols):\n",
    "                dist = abs(pr - r) + abs(pc - c)   # Manhattan\n",
    "                contrib = sign * self.planet_reward_scale / (1.0 + self.planet_reward_decay*dist)\n",
    "                self.planet_reward_map[r, c] += contrib\n",
    "    \n",
    "    def check_valid_position(self, position):\n",
    "        row, col = position\n",
    "\n",
    "        # If RL agent goes out of the map\n",
    "        if row < 0 or col < 0 or row >= self.num_rows or col >= self.num_cols:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    def is_adjacent(self, pos1, pos2):\n",
    "        r1, c1 = pos1\n",
    "        r2, c2 = pos2\n",
    "        return (abs(r1 - r2) == 1 and c1 == c2) or (r1 == r2 and abs(c1 - c2) == 1)\n",
    "\n",
    "\n",
    "    ###############################################################\n",
    "    # OpenAI Gymnasium and Stable Baselines3's required functions #\n",
    "    ###############################################################\n",
    "    def step(self, action):\n",
    "        # --- Decrease 'mission_time_before_self_destruct' time -------------------------------------\n",
    "        self.mission_time_before_self_destruct -= 1\n",
    "\n",
    "        # --- Apply RL agent action -----------------------------------------------------------------\n",
    "        new_pos = np.array(self.state)\n",
    "        if action == 0:     # Forward\n",
    "            new_pos[0] -= 1\n",
    "        elif action == 1:   # Backward\n",
    "            new_pos[0] += 1\n",
    "        elif action == 2:   # Leftward\n",
    "            new_pos[1] -= 1 \n",
    "        elif action == 3:   # Rightward\n",
    "            new_pos[1] += 1\n",
    "\n",
    "        # Check if RL agent is in a valid position\n",
    "        if self.check_valid_position(new_pos):\n",
    "            if all(tuple(new_pos) != e.pos for e in self.entities):\n",
    "                self.state = tuple(new_pos)\n",
    "\n",
    "        #########################################\n",
    "        # Calculate Reward with Reward Function #\n",
    "        #########################################\n",
    "        reward = 0\n",
    "\n",
    "        row, col = self.state\n",
    "        r, c     = self.state\n",
    "        v        = self.vision_radius\n",
    "\n",
    "        exploration_reward = 0\n",
    "\n",
    "        # --- Penalise points for living -------------------------------------\n",
    "        reward -= self.living_penalty\n",
    "\n",
    "        # --- Reward points for every planet visited -------------------------------------\n",
    "        if self.map[row, col] == '#':       # If a planet is visited\n",
    "            self._inject_planet_reward((row, col), sign=-1.0)  # erase its halo\n",
    "            reward += 50\n",
    "            self.map[row, col] = '.'        # Mark planet as visited, so RL agent dosent choose to stay there infinitely and force it to find other planets\n",
    "            self.visited_planets += 1\n",
    "\n",
    "        # --- Penalise points if agent steps into a previously seen region or at the starting position --------------------\n",
    "        if self.seen_map[row, col]:  # already seen\n",
    "            reward -= 0.3\n",
    "\n",
    "        # Penalty for stepping back onto the starting position\n",
    "        if (row, col) == self.start_position:\n",
    "            reward -= 0.3\n",
    "\n",
    "        # --- Penalise points for revisitng an already visited planet -------------------------------------\n",
    "        if self.map[row, col] == '.':\n",
    "            reward -= 1.0  # or some stronger penalty\n",
    "\n",
    "        # --- Reward points for newly explored (first-time seen) cells in vision --------------------------\n",
    "        for dr in range(-v, v + 1):\n",
    "            for dc in range(-v, v + 1):\n",
    "                rr, cc = r + dr, c + dc\n",
    "                if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                    if not self.seen_map[rr, cc]:\n",
    "                        self.seen_map[rr, cc] = True\n",
    "                        exploration_reward += 0.3  # reward per new cell seen\n",
    "\n",
    "        # Discover new planets that just entered vision\n",
    "        for dr in range(-v, v + 1):\n",
    "            for dc in range(-v, v + 1):\n",
    "                rr, cc = r + dr, c + dc\n",
    "                if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                    if self.map[rr, cc] == '#' and (rr, cc) not in self.known_hostile and not self.discovered_planet[rr, cc]:\n",
    "                        self.discovered_planet[rr, cc] = True\n",
    "                        self._inject_planet_reward((rr, cc), sign=+1.0)   # add its reward field\n",
    "        \n",
    "        reward += exploration_reward * 1.5\n",
    "        reward += self.planet_reward_map[row, col]        # dense, cumulative\n",
    "\n",
    "        # --- Penalise points for camping near a corner (2x2 area) -------------------------------------\n",
    "        if (row <= 1 and col <= 1) or \\\n",
    "        (row <= 1 and col >= self.num_cols - 2) or \\\n",
    "        (row >= self.num_rows - 2 and col <= 1) or \\\n",
    "        (row >= self.num_rows - 2 and col >= self.num_cols - 2):\n",
    "            reward -= 0.1\n",
    "\n",
    "\n",
    "        #######################################################################################################\n",
    "        # Handling movement logic and rewards/penalty points related to 'SeparatistShips' and 'RepublicShips' #\n",
    "        #######################################################################################################\n",
    "        # --- a. Move NPCs ('SeparatistShips' and 'RepublicShips') -------------------------------------\n",
    "        proposals = {}   # pos -> entity list\n",
    "        for e in self.entities:\n",
    "            move = e.choose_action_stochastic(self)\n",
    "            new_pos = e.propose_move(move)\n",
    "            # keep inside bounds\n",
    "            r,c = new_pos\n",
    "            if not (0 <= r < self.num_rows and 0 <= c < self.num_cols):\n",
    "                new_pos = e.pos               # bounce\n",
    "            proposals.setdefault(new_pos, []).append(e)\n",
    "\n",
    "        # --- b. Resolve collisions (single occupant rule + adjacency kill) -------------------------------------\n",
    "        #   * single occupant rule\n",
    "        #   * tie‑breaker: Separatist ⇒ victory & occupies; Republic damaged\n",
    "        #   * Republic–Republic collision → first moves, others stay\n",
    "        survivors = []\n",
    "        for dest, group in proposals.items():\n",
    "\n",
    "            if dest == self.state:\n",
    "                survivors.extend(group)        # everyone stays where they are\n",
    "                continue\n",
    "\n",
    "            if len(group) == 1 and dest != self.state:  # free cell\n",
    "                group[0].pos = dest\n",
    "                survivors.append(group[0])\n",
    "                continue\n",
    "\n",
    "            # multiple claimants → resolve\n",
    "            seps = [g for g in group if isinstance(g, SeperatistShip)]\n",
    "            reps = [g for g in group if isinstance(g, RepublicShip)]\n",
    "\n",
    "            if seps:  # at least one Separatist present\n",
    "                # damage republic ships in that cell\n",
    "                for rep in reps:\n",
    "                    continue  # simply omit from survivors list\n",
    "                # one separatist (priority) takes the cell, the rest stay put\n",
    "                seps[0].pos = dest\n",
    "                survivors.extend(seps)  # all separatists survive (only first moved)\n",
    "            else:    # only republics vying for cell\n",
    "                chosen = random.choice(group)\n",
    "                chosen.pos = dest\n",
    "                survivors.append(chosen)\n",
    "                survivors.extend([g for g in group if g is not chosen])\n",
    "\n",
    "        # Remove any NPC ('SeparatistShips' and 'RepublicShips') that ends its move on a hostile planet's lethal square\n",
    "        survivors = [e for e in survivors if not self.is_fatal(e.pos)]\n",
    "\n",
    "        # Updating surviving entities\n",
    "        self.entities = survivors\n",
    "\n",
    "        # 'SeparatistShip' damage 'RepublicShip' or RL agent by neighbouring\n",
    "        to_remove = []\n",
    "        for sep in (e for e in self.entities if isinstance(e, SeperatistShip)):\n",
    "            for rep in (e for e in self.entities if isinstance(e, RepublicShip)):\n",
    "                if self.is_adjacent(sep.pos, rep.pos):\n",
    "                    to_remove.append(rep)\n",
    "            \n",
    "            # Check if RL agent is adjacent to Separatist\n",
    "            if self.is_adjacent(sep.pos, self.state):\n",
    "                self.agent_damage_taken = True\n",
    "                self.damages += 1\n",
    "\n",
    "        for rep in to_remove:\n",
    "            if rep in self.entities:\n",
    "                self.entities.remove(rep)\n",
    "\n",
    "        # --- c. Penalise points for directly adjacent/neighbouring a 'SeparatistShip' (agent takes damage) ----------------------\n",
    "        if self.agent_damage_taken:\n",
    "            reward -= 30\n",
    "            self.agent_damage_taken = False\n",
    "            # done = True\n",
    "\n",
    "\n",
    "        ####################################################################################\n",
    "        # Handling danger map logic, where when a 'SeparatistShip' enters a agent's vision #\n",
    "        ####################################################################################\n",
    "        # --- Penalise points for 'seeing' a 'SeparatistShip' in their vision to encourage/get them to stay away ----------------------\n",
    "        # a. Build the transient danger map exactly as in get_RL_agent_local_observation\n",
    "        #    (you may move that code into a helper so you don't duplicate it).\n",
    "        dang = np.zeros((2*v+1, 2*v+1), dtype=np.float32)\n",
    "        for ship in self.entities:\n",
    "            if not isinstance(ship, SeperatistShip):\n",
    "                continue\n",
    "            sr, sc = ship.pos\n",
    "            rel_r, rel_c = sr - r + v, sc - c + v\n",
    "            if 0 <= rel_r < 2*v+1 and 0 <= rel_c < 2*v+1:\n",
    "                for dr in range(-v, v + 1):\n",
    "                    for dc in range(-v, v + 1):\n",
    "                        dist = abs(dr) + abs(dc)\n",
    "                        if dist > v:\n",
    "                            continue\n",
    "\n",
    "                        cell_r = rel_r + dr\n",
    "                        cell_c = rel_c + dc\n",
    "\n",
    "                        if 0 <= cell_r < 2*v+1 and 0 <= cell_c < 2*v+1:\n",
    "                            penalty = (v - dist + 1) / (v + 1)\n",
    "                            dang[cell_r, cell_c] = max(dang[cell_r, cell_c], penalty)\n",
    "\n",
    "        # b. Convert that map into a negative reward every step.\n",
    "        #    Two common choices:   (pick ONE)\n",
    "        #    • sum of penalties in the window   → harsher when surrounded\n",
    "        #    • max penalty (nearest threat)     → distance-only\n",
    "        danger_strength = np.max(dang)        # np.sum(dang) or np.max(dang)\n",
    "        danger_scale    = -0.3                # tune sign & magnitude\n",
    "\n",
    "        reward += danger_scale * danger_strength\n",
    "\n",
    "\n",
    "        ###################################################################################################\n",
    "        # Handling hostile planets and previous agent's death locations (killed by hostile planets) logic #\n",
    "        ###################################################################################################\n",
    "        # --- Penalise points for being near the death location of a previous agent between sub-episodes of a outer episode -----------------\n",
    "        reward += self.death_halo_map[row, col]\n",
    "\n",
    "        # --- Check if the agent is in a hostile planet's zone ---\n",
    "        if self.is_fatal(self.state):\n",
    "            self.agent_destroyed = True\n",
    "            self.deaths += 1\n",
    "            self._inject_death_halo(self.state)    # remember the death location\n",
    "\n",
    "\n",
    "        if self.agent_destroyed or self.mission_time_before_self_destruct <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        truncated = False\n",
    "        info = {\n",
    "            \"visited_planets\": self.visited_planets,\n",
    "            \"total_planets\": self.total_planets,\n",
    "            \"damages\": self.damages\n",
    "        }\n",
    "\n",
    "        return self.get_RL_agent_local_observation(), reward, done, truncated, info\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        # Clear the screen\n",
    "        self.screen.fill((255, 255, 255))  \n",
    "\n",
    "        agent_r, agent_c = self.state\n",
    "        v = self.vision_radius\n",
    "\n",
    "        # Draw env elements one cell at a time\n",
    "        for row in range(self.num_rows):\n",
    "            for col in range(self.num_cols):\n",
    "                cell_left = col * self.cell_size\n",
    "                cell_top = row * self.cell_size\n",
    "\n",
    "                # If seen_map is True and it's just empty space (i.e. not a planet or visited)\n",
    "                if self.seen_map[row, col] and self.map[row, col] == ' ':\n",
    "                    pygame.draw.rect(self.screen, (255, 200, 200), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "\n",
    "                # Draw the vision radius in yellow (as a background highlight)\n",
    "                if abs(row - agent_r) <= v and abs(col - agent_c) <= v:\n",
    "                    pygame.draw.rect(self.screen, (255, 255, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "\n",
    "                if self.map[row, col] == '#':  # Draw non-visited planet in Light Blue\n",
    "                    pygame.draw.rect(self.screen, (173, 216, 230), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                elif self.map[row, col] == '.':  # Draw visited planet in Green\n",
    "                    pygame.draw.rect(self.screen, (0, 255, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                elif self.map[row, col] == 'S':  # Draw starting position in Black\n",
    "                    pygame.draw.rect(self.screen, (0, 0, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "\n",
    "                if (row, col) == self.state:  # Draw RL agent position in Gray\n",
    "                    pygame.draw.rect(self.screen, (125, 125, 125), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "\n",
    "        # Draw 'SeparatistShips' and 'RepublicShips'\n",
    "        for ship in self.entities:\n",
    "            sr, sc = ship.pos\n",
    "            color = (255,0,0) if isinstance(ship, SeperatistShip) else (0,0,255)\n",
    "            pygame.draw.rect(self.screen, color,\n",
    "                            (sc*self.cell_size, sr*self.cell_size,\n",
    "                            self.cell_size, self.cell_size))\n",
    "\n",
    "        # === Highlight vision radius of each RepublicShip (NEUTRAL ZONE) ===\n",
    "        for ship in self.entities:\n",
    "            if isinstance(ship, RepublicShip):\n",
    "                sr, sc = ship.pos\n",
    "                vr = ship.vision_radius\n",
    "                for dr in range(-vr, vr + 1):\n",
    "                    for dc in range(-vr, vr + 1):\n",
    "                        rr, cc = sr + dr, sc + dc\n",
    "                        if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                            left = cc * self.cell_size\n",
    "                            top  = rr * self.cell_size\n",
    "                            pygame.draw.rect(self.screen, (0, 0, 255), (left, top, self.cell_size, self.cell_size), width=1)\n",
    "\n",
    "        # === Highlight vision radius of each SeperatistShip (DANGER ZONE) ===\n",
    "        for ship in self.entities:\n",
    "            if isinstance(ship, SeperatistShip):\n",
    "                sr, sc = ship.pos\n",
    "                vr = ship.vision_radius\n",
    "                for dr in range(-vr, vr + 1):\n",
    "                    for dc in range(-vr, vr + 1):\n",
    "                        rr, cc = sr + dr, sc + dc\n",
    "                        if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                            left = cc * self.cell_size\n",
    "                            top  = rr * self.cell_size\n",
    "                            pygame.draw.rect(self.screen, (255, 0, 0), (left, top, self.cell_size, self.cell_size), width=1)\n",
    "\n",
    "        # Draw hostile planets\n",
    "        for hr, hc in self.hostile:\n",
    "            pygame.draw.rect(self.screen, (255, 165, 0),\n",
    "                            (hc*self.cell_size, hr*self.cell_size,\n",
    "                            self.cell_size,    self.cell_size))\n",
    "            # outline the 2-tile kill radius\n",
    "            for dr in range(-self.hostile_kill_radius,\n",
    "                            self.hostile_kill_radius+1):\n",
    "                for dc in range(-self.hostile_kill_radius,\n",
    "                                self.hostile_kill_radius+1):\n",
    "                    if max(abs(dr), abs(dc)) <= self.hostile_kill_radius:\n",
    "                        rr, cc = hr+dr, hc+dc\n",
    "                        if 0 <= rr < self.num_rows and 0 <= cc < self.num_cols:\n",
    "                            pygame.draw.rect(self.screen, (255, 165, 0),\n",
    "                                            (cc*self.cell_size, rr*self.cell_size,\n",
    "                                            self.cell_size,    self.cell_size), width=1)\n",
    "                            \n",
    "        # Draw every previous-death square (pink fill, black outline)\n",
    "        for dr, dc in self.death_locations:\n",
    "            left  = dc * self.cell_size\n",
    "            top   = dr * self.cell_size\n",
    "            pygame.draw.rect(self.screen, (255, 105, 180),   # any stand-out colour\n",
    "                             (left, top, self.cell_size, self.cell_size))\n",
    "            pygame.draw.rect(self.screen, (0, 0, 0),         # black outline\n",
    "                             (left, top, self.cell_size, self.cell_size), width=2)\n",
    "                        \n",
    "        pygame.display.update()  # Update the display\n",
    "        # pygame.time.delay(50)   # Slow down the rendering\n",
    "\n",
    "    # def reset(self, *, seed=None, options=None):\n",
    "    #     # Generate a new map\n",
    "    #     self.map = self.generate_map(rows=40, cols=40, num_planets=20)\n",
    "\n",
    "    #     # Reinitialize dependent properties\n",
    "    #     self.num_rows, self.num_cols = self.map.shape\n",
    "    #     self.seen_map[:]           = False\n",
    "    #     self.discovered_planet[:]  = False \n",
    "    #     self.planet_reward_map[:]  = 0.0   \n",
    "        \n",
    "    #     self.start_position = tuple(np.argwhere(self.map == 'S')[0])\n",
    "    #     self.state = self.start_position\n",
    "    #     self.mission_time_before_self_destruct = 300\n",
    "    #     self.agent_damage_taken = False\n",
    "    #     self.agent_destroyed = False\n",
    "    #     self.damages = 0\n",
    "\n",
    "    #     self.total_planets = np.sum(self.map == '#')\n",
    "    #     self.visited_planets = 0\n",
    "\n",
    "    #     self.entities = []\n",
    "    #     self.entity_mgr = EntityManager(self, n_rep=self.n_sep, n_sep=self.n_sep)\n",
    "\n",
    "\n",
    "    #     # Update Pygame screen if dimensions changed\n",
    "    #     self.screen = pygame.display.set_mode(\n",
    "    #         (self.num_cols * self.cell_size, self.num_rows * self.cell_size)\n",
    "    #     )\n",
    "\n",
    "    #     info = {}\n",
    "    #     return self.get_RL_agent_local_observation(), info\n",
    "\n",
    "\n",
    "    #############################################################\n",
    "    # Hard-reset  ➜ called at the start of every OUTER episode #\n",
    "    #############################################################\n",
    "    def hard_reset(self):\n",
    "        # --- Generate a new map ------------------------------------------------------------------------\n",
    "        self.map = self.generate_map(rows=40, cols=40, num_planets=20)\n",
    "\n",
    "        # --- Reinitialize dependent properties ---------------------------------------------------------\n",
    "        # a. re-sample hostile planets\n",
    "        planet_cells   = list(zip(*np.where(self.map == '#')))\n",
    "        n_hostile      = max(1, int(self.hostile_frac * len(planet_cells)))\n",
    "        self.hostile   = set(random.sample(planet_cells, n_hostile))\n",
    "\n",
    "        # b. wipe persistent memories\n",
    "        self.death_halo_map.fill(0.0)\n",
    "        self.hive_memory.fill(0.0)\n",
    "        self.death_locations.clear()\n",
    "\n",
    "        # c. anything purely geographic\n",
    "        self.num_rows, self.num_cols = self.map.shape\n",
    "        self.planet_reward_map.fill(0.0)\n",
    "        self.discovered_planet.fill(False)\n",
    "        self.total_planets = len(planet_cells) - len(self.hostile)\n",
    "\n",
    "        # d. build NPCs\n",
    "        self.entities.clear()\n",
    "        self.entity_mgr = EntityManager(self, n_rep=self.n_rep, n_sep=self.n_sep)\n",
    "\n",
    "        self.visited_planets = 0\n",
    "        self.seen_map.fill(False)\n",
    "        self.discovered_planet.fill(False)\n",
    "        self.agent_damage_taken = False\n",
    "        self.agent_destroyed = False\n",
    "        self.damages = 0\n",
    "        self.mission_time_before_self_destruct = 300\n",
    "\n",
    "        # Spawn the first drone\n",
    "        return self.soft_reset()\n",
    "    \n",
    "    #################################################################\n",
    "    # Soft-reset  ➜ called at the start of every INNER/SUB episode #\n",
    "    #################################################################\n",
    "    def soft_reset(self):\n",
    "        \"\"\"Spawn a new drone but keep all global memories.\"\"\"\n",
    "        # --- Reinitialize dependent properties ---------------------------------------------------------\n",
    "        self.state                   = self.start_position\n",
    "        self.agent_damage_taken      = False\n",
    "        self.agent_destroyed         = False\n",
    "        self.mission_time_before_self_destruct = 300\n",
    "\n",
    "        # new drone, new local entities\n",
    "        self.entities.clear()\n",
    "        self.entity_mgr = EntityManager(self, n_rep=self.n_rep, n_sep=self.n_sep)\n",
    "\n",
    "        info = {\n",
    "            \"soft_reset\"     : True,\n",
    "            \"visited_planets\": self.visited_planets,   # cumulative\n",
    "            \"total_planets\"  : self.total_planets,\n",
    "            \"damages\"        : self.damages\n",
    "        }\n",
    "        return self.get_RL_agent_local_observation(), info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuterRimEnvWithMetaEpisodes(OuterRimEnv):    \n",
    "    def __init__(self, n_sep: int, n_rep: int, *, sub_limit: int = 10):\n",
    "        super().__init__(n_sep, n_rep)\n",
    "        self.sub_limit   = sub_limit\n",
    "        self.sub_done    = 0               # counts soft-resets within one galaxy\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        # Always start with a hard reset (new galaxy) for the *outer* episode\n",
    "        if seed is not None:\n",
    "            super().reset(seed=seed)\n",
    "        obs, info = self.hard_reset()\n",
    "        self.sub_done = 0\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, rew, done, trunc, info = super().step(action)\n",
    "\n",
    "        if done:                               # drone died / timeout\n",
    "            self.sub_done += 1\n",
    "            if self.sub_done < self.sub_limit:\n",
    "                # ---------- soft reset inside the same galaxy ----------\n",
    "                obs, info = self.soft_reset()\n",
    "                done      = False              # ← keep outer episode running\n",
    "            # else: leave done=True → SB3 will call reset() → new galaxy\n",
    "\n",
    "        return obs, rew, done, trunc, info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7f7c3",
   "metadata": {},
   "source": [
    "### Testing the Outer Rim RL Environment if it works with a baseline algorithm that takes random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = OuterRimEnvWithMetaEpisodes(n_sep=2, n_rep=2, sub_limit=5)\n",
    "\n",
    "# episodes = 3\n",
    "# for episode in range(1, episodes+1):\n",
    "#     # Initialise starting state of the RL agent in the RL Environment before an episode, done to false, and starting \n",
    "#     # episode score to 0\n",
    "#     obs, _ = env.reset()    # → hard_reset (new galaxy)\n",
    "#     # print(f\"Initial State: {obs}\")\n",
    "#     done = False\n",
    "#     outer_episode_score = 0.0\n",
    "\n",
    "#     inner_episode = 1\n",
    "#     inner_episode_score = 0.0\n",
    "#     inner_episode_steps = 0\n",
    "#     inner_episode_damages = 0\n",
    "\n",
    "#     # During an episode:\n",
    "#     while not done:\n",
    "#         env.render()\n",
    "#         # RL agent determines action to take\n",
    "#         # - In this case, we are randomly sampling an action to take by our RL agent in the RL Environment (this line of\n",
    "#         #   code defines that baseline algorithm that takes random actions (instead of an RL algorithm))\n",
    "#         action = env.action_space.sample()\n",
    "#         # RL Environment generates the next state and reward gained upon taking the action in the current state\n",
    "#         obs, reward, done, truncated, info = env.step(action)\n",
    "#         # Append the reward gained upon taking the action in the current state to the cumulative episode date\n",
    "#         inner_episode_score += reward\n",
    "#         outer_episode_score += reward\n",
    "#         inner_episode_steps += 1\n",
    "\n",
    "#         ###########################################\n",
    "#         # Detect the moment a soft-reset happened #\n",
    "#         ###########################################\n",
    "#         if info.get(\"soft_reset\", False):\n",
    "#             print(f\"\\n--- Inner Episode {inner_episode} ---\")\n",
    "#             print(f\"Outer Episode: {episode} | Inner Episode Score: {inner_episode_score:.2f} | \"\n",
    "#                   f\"Cumulative Score So Far: {outer_episode_score:.2f} | \"\n",
    "#                   f\"Planets Found so far: {info['visited_planets']}/{info['total_planets']} | \"\n",
    "#                   f\"Damages to Inner Episode Drone: {info['damages'] - inner_episode_damages} | \"\n",
    "#                   f\"Steps Survived: {inner_episode_steps}\")\n",
    "            \n",
    "#             inner_episode += 1\n",
    "#             inner_episode_score = 0.0\n",
    "#             inner_episode_steps = 0\n",
    "#             inner_episode_damages = info['damages']\n",
    "\n",
    "#     print(f\"\\n--- Inner Episode {inner_episode} (Final) ---\")\n",
    "#     print(f\"Outer Episode: {episode} | Inner Episode Score: {inner_episode_score:.2f} | \"\n",
    "#           f\"Cumulative Score So Far: {outer_episode_score:.2f} | \"\n",
    "#           f\"Planets Found so far: {info['visited_planets']}/{info['total_planets']} | \"\n",
    "#           f\"Damages to Inner Episode Drone: {info['damages'] - inner_episode_damages} | \"\n",
    "#           f\"Steps Survived: {inner_episode_steps}\")\n",
    "    \n",
    "#     print(f\"\\n=== End of Outer Episode {episode} | Total Return: {outer_episode_score:.2f} ===\")\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16aa0bc",
   "metadata": {},
   "source": [
    "## Train a PPO DRL algorithm in a RL Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df61e8",
   "metadata": {},
   "source": [
    "### Vectorising and Normalising rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: OuterRimEnvWithMetaEpisodes(n_sep=2, n_rep=2, sub_limit=15)])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_reward=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ad83f",
   "metadata": {},
   "source": [
    "### For logging purposes of the training process of the PPO DRL algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca12d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Star_Wars_Galaxy_Phase_3\\logs\n"
     ]
    }
   ],
   "source": [
    "# Stating the path where we want to store our training logs files in the local folder './Training_Project_3_Custom/logs'\n",
    "log_path = os.path.join('Training_Star_Wars_Galaxy_Phase_3', 'logs')\n",
    "print(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d81e42",
   "metadata": {},
   "source": [
    "### Creating the PPO DRL algorithm in the RL Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# What does each of the parameters in the 'PPO' DRL algorithm class mean?\n",
    "# - 'policy' (e.g. 'MlpPolicy'  - refers to the learning architecture used a the policy of the RL algorithm, which in this\n",
    "#               or 'CnnPolicy')   is FNN/MLP\n",
    "# - 'env'                       - refers to the RL environment to train the RL algorithm in\n",
    "# - 'verbose'                   - controls how much information is printed to the console/log during training\n",
    "#                                 -> 'verbose=0' means 'Silent', no output at all\n",
    "#                                 -> 'verbose=1' means 'Info', shows key training events: episode rewards, updates, losses, etc.\n",
    "#                                 -> 'verbose=2' means 'Debug' shows more detailed info like hyperparameters, rollout steps, and internal logs\n",
    "# - 'tensorboard_log'           - states to do the training logging in Tensorboard\n",
    "PPO_DRL_model = PPO('MultiInputPolicy', \n",
    "                    env, \n",
    "                    verbose=1, \n",
    "                    tensorboard_log=log_path\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c09c8c",
   "metadata": {},
   "source": [
    "### Training the PPO DRL algorithm in the RL Environment to become a PPO DRL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training_Star_Wars_Galaxy_Phase_3\\logs\\PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 548  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 3    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 468        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08352044 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.517     |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0619    |\n",
      "|    n_updates            | 2460       |\n",
      "|    policy_gradient_loss | -0.0459    |\n",
      "|    value_loss           | 0.0584     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 396        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04812429 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.407     |\n",
      "|    explained_variance   | 0.133      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0536    |\n",
      "|    n_updates            | 2470       |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.0133     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 366        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06423017 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.511     |\n",
      "|    explained_variance   | 0.0555     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0359    |\n",
      "|    n_updates            | 2480       |\n",
      "|    policy_gradient_loss | -0.0379    |\n",
      "|    value_loss           | 0.0361     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060872167 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.575      |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.026      |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.0227      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048067257 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | -0.493      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.049      |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.0469     |\n",
      "|    value_loss           | 0.00938     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038128234 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.474      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0263      |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.0679      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046658836 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.609      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0412     |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04931156 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.563     |\n",
      "|    explained_variance   | 0.793      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0631    |\n",
      "|    n_updates            | 2530       |\n",
      "|    policy_gradient_loss | -0.0315    |\n",
      "|    value_loss           | 0.0155     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 262        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04012845 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.496     |\n",
      "|    explained_variance   | 0.71       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0499    |\n",
      "|    n_updates            | 2540       |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.00784    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059277706 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.621      |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0436     |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 0.0341      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047013916 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.59       |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00986    |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 259       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0681057 |\n",
      "|    clip_fraction        | 0.265     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.4      |\n",
      "|    explained_variance   | 0.298     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0434   |\n",
      "|    n_updates            | 2570      |\n",
      "|    policy_gradient_loss | -0.0399   |\n",
      "|    value_loss           | 0.0378    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 262        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 109        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03411883 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.609     |\n",
      "|    explained_variance   | -1.79      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.07      |\n",
      "|    n_updates            | 2580       |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.00821    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 115        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08325187 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.543     |\n",
      "|    explained_variance   | 0.243      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0788    |\n",
      "|    n_updates            | 2590       |\n",
      "|    policy_gradient_loss | -0.0499    |\n",
      "|    value_loss           | 0.04       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035586517 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.639      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0503     |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.014       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042893507 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0331     |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.0218      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 131        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07012258 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.643     |\n",
      "|    explained_variance   | 0.775      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0593    |\n",
      "|    n_updates            | 2620       |\n",
      "|    policy_gradient_loss | -0.0458    |\n",
      "|    value_loss           | 0.0198     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07018731 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.723     |\n",
      "|    explained_variance   | 0.267      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0638    |\n",
      "|    n_updates            | 2630       |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.0173     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048701216 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.745      |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 0.0245      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 148        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04252884 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.622     |\n",
      "|    explained_variance   | 0.575      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.023     |\n",
      "|    n_updates            | 2650       |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 0.0125     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053095564 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0495     |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    value_loss           | 0.0185      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041124433 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | -3.9        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0582     |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 0.00289     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 168        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05967091 |\n",
      "|    clip_fraction        | 0.28       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.703     |\n",
      "|    explained_variance   | 0.67       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0311    |\n",
      "|    n_updates            | 2680       |\n",
      "|    policy_gradient_loss | -0.0433    |\n",
      "|    value_loss           | 0.0318     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025116425 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.932      |\n",
      "|    explained_variance   | -0.0158     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0444     |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 0.00224     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045965865 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.042      |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    value_loss           | 0.0346      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053975943 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.672      |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0542     |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 0.0202      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 296        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 193        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07864332 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.447     |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0635    |\n",
      "|    n_updates            | 2720       |\n",
      "|    policy_gradient_loss | -0.0523    |\n",
      "|    value_loss           | 0.0328     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.072392344 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.065      |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 0.014       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 300      |\n",
      "|    iterations           | 30       |\n",
      "|    time_elapsed         | 204      |\n",
      "|    total_timesteps      | 61440    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.069419 |\n",
      "|    clip_fraction        | 0.353    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.566   |\n",
      "|    explained_variance   | 0.824    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.0192  |\n",
      "|    n_updates            | 2740     |\n",
      "|    policy_gradient_loss | -0.0537  |\n",
      "|    value_loss           | 0.0249   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030927403 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.052      |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.00808     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 304       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 214       |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0926287 |\n",
      "|    clip_fraction        | 0.351     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.571    |\n",
      "|    explained_variance   | 0.824     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0847   |\n",
      "|    n_updates            | 2760      |\n",
      "|    policy_gradient_loss | -0.0417   |\n",
      "|    value_loss           | 0.0195    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 220        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05228553 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.456     |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.031     |\n",
      "|    n_updates            | 2770       |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.0539     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062801965 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.473      |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0582     |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 0.0256      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05347041 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.423     |\n",
      "|    explained_variance   | 0.683      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0489    |\n",
      "|    n_updates            | 2790       |\n",
      "|    policy_gradient_loss | -0.0379    |\n",
      "|    value_loss           | 0.0483     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 238        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04339201 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.489     |\n",
      "|    explained_variance   | 0.459      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0285    |\n",
      "|    n_updates            | 2800       |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.0534     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 305        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 247        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05161031 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.457     |\n",
      "|    explained_variance   | 0.606      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0566    |\n",
      "|    n_updates            | 2810       |\n",
      "|    policy_gradient_loss | -0.0436    |\n",
      "|    value_loss           | 0.0166     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 305        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 254        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05221628 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.421     |\n",
      "|    explained_variance   | 0.201      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0298     |\n",
      "|    n_updates            | 2820       |\n",
      "|    policy_gradient_loss | -0.0365    |\n",
      "|    value_loss           | 0.0257     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 305       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 261       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0771779 |\n",
      "|    clip_fraction        | 0.28      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.475    |\n",
      "|    explained_variance   | 0.433     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0636   |\n",
      "|    n_updates            | 2830      |\n",
      "|    policy_gradient_loss | -0.0406   |\n",
      "|    value_loss           | 0.0308    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.075539336 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.385      |\n",
      "|    explained_variance   | -0.698      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0606     |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.0228      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 305        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 274        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04889989 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.502     |\n",
      "|    explained_variance   | 0.639      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0349    |\n",
      "|    n_updates            | 2850       |\n",
      "|    policy_gradient_loss | -0.0332    |\n",
      "|    value_loss           | 0.0491     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048985127 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.593      |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0261     |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.0155      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053819902 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0157      |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 302        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 298        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21198413 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.36      |\n",
      "|    explained_variance   | -0.54      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0588    |\n",
      "|    n_updates            | 2880       |\n",
      "|    policy_gradient_loss | -0.0388    |\n",
      "|    value_loss           | 0.012      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.072087236 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.502      |\n",
      "|    explained_variance   | -0.287      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0647     |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 0.0292      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 304       |\n",
      "|    iterations           | 46        |\n",
      "|    time_elapsed         | 309       |\n",
      "|    total_timesteps      | 94208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0513078 |\n",
      "|    clip_fraction        | 0.249     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.671    |\n",
      "|    explained_variance   | 0.349     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0386   |\n",
      "|    n_updates            | 2900      |\n",
      "|    policy_gradient_loss | -0.0257   |\n",
      "|    value_loss           | 0.00427   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060626063 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0217     |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.0903      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044973448 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.367      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0326     |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 0.047       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041451897 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.48       |\n",
      "|    explained_variance   | -0.0474     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0403     |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    value_loss           | 0.0485      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058616053 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.636      |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0245     |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.0275      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 305       |\n",
      "|    iterations           | 51        |\n",
      "|    time_elapsed         | 341       |\n",
      "|    total_timesteps      | 104448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0901998 |\n",
      "|    clip_fraction        | 0.187     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.346    |\n",
      "|    explained_variance   | -4.91     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00257  |\n",
      "|    n_updates            | 2950      |\n",
      "|    policy_gradient_loss | -0.0191   |\n",
      "|    value_loss           | 0.00371   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 346        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06557639 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.586     |\n",
      "|    explained_variance   | 0.697      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0394    |\n",
      "|    n_updates            | 2960       |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    value_loss           | 0.0387     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 308        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 352        |\n",
      "|    total_timesteps      | 108544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04404511 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.704     |\n",
      "|    explained_variance   | 0.615      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0479    |\n",
      "|    n_updates            | 2970       |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.0552     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 308        |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 358        |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04892879 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.656     |\n",
      "|    explained_variance   | 0.611      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0129     |\n",
      "|    n_updates            | 2980       |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    value_loss           | 0.0773     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043167368 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | -0.0879     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.054      |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.00982     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 371         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.075552866 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0673     |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 0.0277      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 377         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038032852 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.7        |\n",
      "|    explained_variance   | -0.177      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0535     |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.0233      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058613885 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0639     |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    value_loss           | 0.0344      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059508577 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | -0.12       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0123      |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    value_loss           | 0.0768      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 396        |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06890498 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.536     |\n",
      "|    explained_variance   | 0.367      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0364    |\n",
      "|    n_updates            | 3040       |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    value_loss           | 0.0261     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 402        |\n",
      "|    total_timesteps      | 124928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07121532 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.612     |\n",
      "|    explained_variance   | -0.463     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0486    |\n",
      "|    n_updates            | 3050       |\n",
      "|    policy_gradient_loss | -0.0364    |\n",
      "|    value_loss           | 0.0158     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057479613 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.494      |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0452     |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.0581      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 414        |\n",
      "|    total_timesteps      | 129024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07865314 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.463     |\n",
      "|    explained_variance   | -0.73      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0529    |\n",
      "|    n_updates            | 3070       |\n",
      "|    policy_gradient_loss | -0.0465    |\n",
      "|    value_loss           | 0.0117     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056108665 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.463      |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0326     |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 0.0339      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 430        |\n",
      "|    total_timesteps      | 133120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06808379 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.668     |\n",
      "|    explained_variance   | 0.0675     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0904    |\n",
      "|    n_updates            | 3090       |\n",
      "|    policy_gradient_loss | -0.0391    |\n",
      "|    value_loss           | 0.0114     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036338642 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.612      |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0433     |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 0.0274      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052350916 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0712     |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 0.00921     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 310       |\n",
      "|    iterations           | 68        |\n",
      "|    time_elapsed         | 449       |\n",
      "|    total_timesteps      | 139264    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0434798 |\n",
      "|    clip_fraction        | 0.234     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.569    |\n",
      "|    explained_variance   | 0.768     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.028    |\n",
      "|    n_updates            | 3120      |\n",
      "|    policy_gradient_loss | -0.0308   |\n",
      "|    value_loss           | 0.0179    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034800023 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.743      |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0465     |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 0.00516     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 462        |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07439476 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0807    |\n",
      "|    n_updates            | 3140       |\n",
      "|    policy_gradient_loss | -0.0484    |\n",
      "|    value_loss           | 0.0222     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 468        |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07584727 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.391     |\n",
      "|    explained_variance   | -0.0917    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0384    |\n",
      "|    n_updates            | 3150       |\n",
      "|    policy_gradient_loss | -0.035     |\n",
      "|    value_loss           | 0.0271     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 309       |\n",
      "|    iterations           | 72        |\n",
      "|    time_elapsed         | 476       |\n",
      "|    total_timesteps      | 147456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1075829 |\n",
      "|    clip_fraction        | 0.29      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.437    |\n",
      "|    explained_variance   | 0.174     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0504   |\n",
      "|    n_updates            | 3160      |\n",
      "|    policy_gradient_loss | -0.0452   |\n",
      "|    value_loss           | 0.0617    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 485        |\n",
      "|    total_timesteps      | 149504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06142675 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.499     |\n",
      "|    explained_variance   | 0.267      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0627    |\n",
      "|    n_updates            | 3170       |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    value_loss           | 0.0546     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 492         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050214335 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.447      |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0437     |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    value_loss           | 0.0607      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058907907 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0634     |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    value_loss           | 0.0317      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043399263 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.0755      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0396     |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.00892     |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 308      |\n",
      "|    iterations           | 77       |\n",
      "|    time_elapsed         | 511      |\n",
      "|    total_timesteps      | 157696   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.056284 |\n",
      "|    clip_fraction        | 0.267    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.451   |\n",
      "|    explained_variance   | 0.378    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.0747  |\n",
      "|    n_updates            | 3210     |\n",
      "|    policy_gradient_loss | -0.0386  |\n",
      "|    value_loss           | 0.0234   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 518         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045607936 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | -0.363      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0459     |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 0.00764     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 308        |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 523        |\n",
      "|    total_timesteps      | 161792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05344227 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.578     |\n",
      "|    explained_variance   | 0.471      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0328    |\n",
      "|    n_updates            | 3230       |\n",
      "|    policy_gradient_loss | -0.0406    |\n",
      "|    value_loss           | 0.0255     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 530         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026828313 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.847      |\n",
      "|    explained_variance   | -1.56       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0681     |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 0.00341     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040790737 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.695      |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0451     |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    value_loss           | 0.0325      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 543        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07139942 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.658     |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0348    |\n",
      "|    n_updates            | 3260       |\n",
      "|    policy_gradient_loss | -0.0356    |\n",
      "|    value_loss           | 0.0506     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 549         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055191167 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.441      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0528     |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.026       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 84         |\n",
      "|    time_elapsed         | 555        |\n",
      "|    total_timesteps      | 172032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03262981 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.475     |\n",
      "|    explained_variance   | -0.124     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0356    |\n",
      "|    n_updates            | 3280       |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 0.013      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 85         |\n",
      "|    time_elapsed         | 561        |\n",
      "|    total_timesteps      | 174080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15165395 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.391     |\n",
      "|    explained_variance   | 0.688      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0557    |\n",
      "|    n_updates            | 3290       |\n",
      "|    policy_gradient_loss | -0.0548    |\n",
      "|    value_loss           | 0.0294     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 567        |\n",
      "|    total_timesteps      | 176128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06132822 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.449     |\n",
      "|    explained_variance   | 0.22       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0216    |\n",
      "|    n_updates            | 3300       |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 0.0538     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 573        |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07753525 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.405     |\n",
      "|    explained_variance   | -0.227     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0583    |\n",
      "|    n_updates            | 3310       |\n",
      "|    policy_gradient_loss | -0.039     |\n",
      "|    value_loss           | 0.0118     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046430066 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.439      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.048      |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.0179      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 587        |\n",
      "|    total_timesteps      | 182272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04496883 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.619     |\n",
      "|    explained_variance   | 0.289      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0496    |\n",
      "|    n_updates            | 3330       |\n",
      "|    policy_gradient_loss | -0.0418    |\n",
      "|    value_loss           | 0.0114     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 595        |\n",
      "|    total_timesteps      | 184320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07487972 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.629     |\n",
      "|    explained_variance   | 0.49       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0853    |\n",
      "|    n_updates            | 3340       |\n",
      "|    policy_gradient_loss | -0.042     |\n",
      "|    value_loss           | 0.0397     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 601        |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06873508 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.548     |\n",
      "|    explained_variance   | 0.79       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0612    |\n",
      "|    n_updates            | 3350       |\n",
      "|    policy_gradient_loss | -0.036     |\n",
      "|    value_loss           | 0.0294     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 609         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046229266 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.645      |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0627     |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046275564 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0304     |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 0.0302      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 621        |\n",
      "|    total_timesteps      | 192512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03699883 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.83      |\n",
      "|    explained_variance   | -0.823     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0492    |\n",
      "|    n_updates            | 3380       |\n",
      "|    policy_gradient_loss | -0.0314    |\n",
      "|    value_loss           | 0.00451    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 628        |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04107642 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.778     |\n",
      "|    explained_variance   | 0.58       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0552    |\n",
      "|    n_updates            | 3390       |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.0338     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 634        |\n",
      "|    total_timesteps      | 196608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04873666 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.672     |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0457    |\n",
      "|    n_updates            | 3400       |\n",
      "|    policy_gradient_loss | -0.0369    |\n",
      "|    value_loss           | 0.0361     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 641         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036505602 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.525      |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.272       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 648         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.079160064 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00161    |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.0299      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 655         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057649206 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0661     |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.0171      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 661        |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05216361 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.742     |\n",
      "|    explained_variance   | 0.848      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0235    |\n",
      "|    n_updates            | 3440       |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    value_loss           | 0.0171     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055610165 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.471      |\n",
      "|    explained_variance   | -0.798      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0922      |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    value_loss           | 0.0176      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036375366 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0354     |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.0187      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033480395 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.595      |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -2.96e-05   |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.0833      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 687        |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06995575 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.456     |\n",
      "|    explained_variance   | 0.724      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0516    |\n",
      "|    n_updates            | 3480       |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    value_loss           | 0.0255     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 692        |\n",
      "|    total_timesteps      | 215040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08756089 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.474     |\n",
      "|    explained_variance   | -0.542     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0331    |\n",
      "|    n_updates            | 3490       |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 0.022      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 698         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056312636 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.595      |\n",
      "|    explained_variance   | 0.0259      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0091     |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    value_loss           | 0.0257      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 703         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042628624 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.643      |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0391     |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 0.0526      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 709        |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08607765 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.456     |\n",
      "|    explained_variance   | -0.631     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0514     |\n",
      "|    n_updates            | 3520       |\n",
      "|    policy_gradient_loss | -0.023     |\n",
      "|    value_loss           | 0.00956    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 715         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039175417 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.44       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0335     |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 110        |\n",
      "|    time_elapsed         | 722        |\n",
      "|    total_timesteps      | 225280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03130409 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.796     |\n",
      "|    explained_variance   | 0.218      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.048     |\n",
      "|    n_updates            | 3540       |\n",
      "|    policy_gradient_loss | -0.0277    |\n",
      "|    value_loss           | 0.0131     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 312        |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 728        |\n",
      "|    total_timesteps      | 227328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06245056 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.586     |\n",
      "|    explained_variance   | 0.539      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0573    |\n",
      "|    n_updates            | 3550       |\n",
      "|    policy_gradient_loss | -0.0268    |\n",
      "|    value_loss           | 0.0835     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 733         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044373825 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0297     |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.0237      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 738        |\n",
      "|    total_timesteps      | 231424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06614735 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.625     |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0442    |\n",
      "|    n_updates            | 3570       |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    value_loss           | 0.0271     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033419184 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.598      |\n",
      "|    explained_variance   | -0.918      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0111     |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.0326      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 313       |\n",
      "|    iterations           | 115       |\n",
      "|    time_elapsed         | 750       |\n",
      "|    total_timesteps      | 235520    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0667736 |\n",
      "|    clip_fraction        | 0.255     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.436    |\n",
      "|    explained_variance   | 0.643     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0689   |\n",
      "|    n_updates            | 3590      |\n",
      "|    policy_gradient_loss | -0.0402   |\n",
      "|    value_loss           | 0.0344    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 755         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.071749255 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.536      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0141     |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.0478      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 117        |\n",
      "|    time_elapsed         | 761        |\n",
      "|    total_timesteps      | 239616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03729795 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.351     |\n",
      "|    explained_variance   | 0.578      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0196    |\n",
      "|    n_updates            | 3610       |\n",
      "|    policy_gradient_loss | -0.0251    |\n",
      "|    value_loss           | 0.0688     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 766         |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028692355 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.416      |\n",
      "|    explained_variance   | -0.132      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0244     |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 0.0184      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 772         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049938854 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.461      |\n",
      "|    explained_variance   | 0.0732      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0402     |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 120        |\n",
      "|    time_elapsed         | 778        |\n",
      "|    total_timesteps      | 245760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06598187 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.596     |\n",
      "|    explained_variance   | -0.0957    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0178    |\n",
      "|    n_updates            | 3640       |\n",
      "|    policy_gradient_loss | -0.0365    |\n",
      "|    value_loss           | 0.0431     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 315       |\n",
      "|    iterations           | 121       |\n",
      "|    time_elapsed         | 785       |\n",
      "|    total_timesteps      | 247808    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0847764 |\n",
      "|    clip_fraction        | 0.248     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.473    |\n",
      "|    explained_variance   | 0.336     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0672   |\n",
      "|    n_updates            | 3650      |\n",
      "|    policy_gradient_loss | -0.0402   |\n",
      "|    value_loss           | 0.0838    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 790         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037720088 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.76       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0193     |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.0264      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 796         |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059953544 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.62       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0496     |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.0153      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 802        |\n",
      "|    total_timesteps      | 253952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04220206 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.596     |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0239    |\n",
      "|    n_updates            | 3680       |\n",
      "|    policy_gradient_loss | -0.0362    |\n",
      "|    value_loss           | 0.0354     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 808         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050678805 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.678      |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0649     |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.0357      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 814         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063976124 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.708      |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0611     |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.0184      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 127        |\n",
      "|    time_elapsed         | 820        |\n",
      "|    total_timesteps      | 260096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05856643 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.254     |\n",
      "|    explained_variance   | -0.582     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0568    |\n",
      "|    n_updates            | 3710       |\n",
      "|    policy_gradient_loss | -0.0354    |\n",
      "|    value_loss           | 0.0724     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 826         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.080366984 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00448    |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 0.0347      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 832         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060574345 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.374      |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0461     |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.0311      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 838         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048607312 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000172    |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 0.0298      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 317       |\n",
      "|    iterations           | 131       |\n",
      "|    time_elapsed         | 844       |\n",
      "|    total_timesteps      | 268288    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0575835 |\n",
      "|    clip_fraction        | 0.243     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.452    |\n",
      "|    explained_variance   | 0.656     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0477   |\n",
      "|    n_updates            | 3750      |\n",
      "|    policy_gradient_loss | -0.0386   |\n",
      "|    value_loss           | 0.0261    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 132        |\n",
      "|    time_elapsed         | 850        |\n",
      "|    total_timesteps      | 270336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05619991 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.623     |\n",
      "|    explained_variance   | -0.627     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0719    |\n",
      "|    n_updates            | 3760       |\n",
      "|    policy_gradient_loss | -0.0385    |\n",
      "|    value_loss           | 0.00851    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 856        |\n",
      "|    total_timesteps      | 272384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05780863 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.615     |\n",
      "|    explained_variance   | 0.631      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0656    |\n",
      "|    n_updates            | 3770       |\n",
      "|    policy_gradient_loss | -0.0369    |\n",
      "|    value_loss           | 0.0162     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 862         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046542488 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.022      |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.0132      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 868         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045340948 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | -0.258      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0384     |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0076      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 874         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047624648 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.559      |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00555     |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.0569      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 318       |\n",
      "|    iterations           | 137       |\n",
      "|    time_elapsed         | 880       |\n",
      "|    total_timesteps      | 280576    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0467842 |\n",
      "|    clip_fraction        | 0.239     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.656    |\n",
      "|    explained_variance   | -0.0327   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0242   |\n",
      "|    n_updates            | 3810      |\n",
      "|    policy_gradient_loss | -0.0317   |\n",
      "|    value_loss           | 0.0168    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 886         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056341637 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000355   |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.000549   |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 892        |\n",
      "|    total_timesteps      | 284672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04172668 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.446     |\n",
      "|    explained_variance   | -0.0566    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0538    |\n",
      "|    n_updates            | 3830       |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 0.0168     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 899         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.093165435 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.559      |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0517     |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    value_loss           | 0.0275      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 905         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047774926 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.525      |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    value_loss           | 0.0421      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 912         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045163423 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.413      |\n",
      "|    explained_variance   | -0.324      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0555     |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.015       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 918         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.067761615 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.455      |\n",
      "|    explained_variance   | 0.0102      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00696     |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 925         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.068225324 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.556      |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0674     |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 0.054       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 145        |\n",
      "|    time_elapsed         | 931        |\n",
      "|    total_timesteps      | 296960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04431591 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.548     |\n",
      "|    explained_variance   | 0.492      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0353    |\n",
      "|    n_updates            | 3890       |\n",
      "|    policy_gradient_loss | -0.0338    |\n",
      "|    value_loss           | 0.117      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 936         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059810482 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.372      |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.036      |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.0329      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 147        |\n",
      "|    time_elapsed         | 943        |\n",
      "|    total_timesteps      | 301056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06897542 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.346     |\n",
      "|    explained_variance   | 0.0122     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00443   |\n",
      "|    n_updates            | 3910       |\n",
      "|    policy_gradient_loss | -0.037     |\n",
      "|    value_loss           | 0.058      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 949        |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07437195 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.498     |\n",
      "|    explained_variance   | 0.282      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0505     |\n",
      "|    n_updates            | 3920       |\n",
      "|    policy_gradient_loss | -0.047     |\n",
      "|    value_loss           | 0.137      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 149        |\n",
      "|    time_elapsed         | 955        |\n",
      "|    total_timesteps      | 305152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18878569 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.392     |\n",
      "|    explained_variance   | -0.028     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00678    |\n",
      "|    n_updates            | 3930       |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    value_loss           | 0.0442     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 961         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044316635 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | -0.0141     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0522     |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 0.0425      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 967         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061924234 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.415      |\n",
      "|    explained_variance   | -0.495      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0303     |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.0378      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 974        |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09160817 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.399     |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0539    |\n",
      "|    n_updates            | 3960       |\n",
      "|    policy_gradient_loss | -0.0256    |\n",
      "|    value_loss           | 0.052      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 980         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050330855 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.382      |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.016      |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 0.05        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 154        |\n",
      "|    time_elapsed         | 987        |\n",
      "|    total_timesteps      | 315392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06376049 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.337     |\n",
      "|    explained_variance   | 0.321      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0254    |\n",
      "|    n_updates            | 3980       |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.0238     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 155        |\n",
      "|    time_elapsed         | 994        |\n",
      "|    total_timesteps      | 317440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07016901 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.409     |\n",
      "|    explained_variance   | 0.275      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0523    |\n",
      "|    n_updates            | 3990       |\n",
      "|    policy_gradient_loss | -0.0392    |\n",
      "|    value_loss           | 0.04       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 1000        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058219835 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.552      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0741     |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.0147      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 157        |\n",
      "|    time_elapsed         | 1006       |\n",
      "|    total_timesteps      | 321536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05171287 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.468     |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0194    |\n",
      "|    n_updates            | 4010       |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    value_loss           | 0.0186     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 319       |\n",
      "|    iterations           | 158       |\n",
      "|    time_elapsed         | 1011      |\n",
      "|    total_timesteps      | 323584    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0575094 |\n",
      "|    clip_fraction        | 0.206     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.484    |\n",
      "|    explained_variance   | 0.184     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0377   |\n",
      "|    n_updates            | 4020      |\n",
      "|    policy_gradient_loss | -0.0159   |\n",
      "|    value_loss           | 0.137     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 159        |\n",
      "|    time_elapsed         | 1018       |\n",
      "|    total_timesteps      | 325632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08857635 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.371     |\n",
      "|    explained_variance   | 0.615      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0615    |\n",
      "|    n_updates            | 4030       |\n",
      "|    policy_gradient_loss | -0.0419    |\n",
      "|    value_loss           | 0.0595     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 1024       |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07166867 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.409     |\n",
      "|    explained_variance   | 0.621      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0522    |\n",
      "|    n_updates            | 4040       |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.0232     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 1030        |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029061534 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.395      |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0297     |\n",
      "|    n_updates            | 4050        |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.0277      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 162        |\n",
      "|    time_elapsed         | 1037       |\n",
      "|    total_timesteps      | 331776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04941064 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.384     |\n",
      "|    explained_variance   | 0.674      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0152     |\n",
      "|    n_updates            | 4060       |\n",
      "|    policy_gradient_loss | -0.0339    |\n",
      "|    value_loss           | 0.0319     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 1044        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.075667664 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.427      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0663     |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.019       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 164        |\n",
      "|    time_elapsed         | 1050       |\n",
      "|    total_timesteps      | 335872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06049688 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.45      |\n",
      "|    explained_variance   | 0.397      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0427     |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    value_loss           | 0.138      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 1056        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039129928 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0414     |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 166        |\n",
      "|    time_elapsed         | 1062       |\n",
      "|    total_timesteps      | 339968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07753788 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.465     |\n",
      "|    explained_variance   | 0.544      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0706    |\n",
      "|    n_updates            | 4100       |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.0376     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 1069        |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047799695 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | -0.329      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.00937     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 168        |\n",
      "|    time_elapsed         | 1076       |\n",
      "|    total_timesteps      | 344064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06407823 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.499     |\n",
      "|    explained_variance   | 0.613      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0362    |\n",
      "|    n_updates            | 4120       |\n",
      "|    policy_gradient_loss | -0.0417    |\n",
      "|    value_loss           | 0.0359     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 169        |\n",
      "|    time_elapsed         | 1082       |\n",
      "|    total_timesteps      | 346112     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08618219 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.38      |\n",
      "|    explained_variance   | 0.792      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0358    |\n",
      "|    n_updates            | 4130       |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.0198     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 1088        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041056097 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.0457      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0819     |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.00685     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 171        |\n",
      "|    time_elapsed         | 1098       |\n",
      "|    total_timesteps      | 350208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21529049 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.395     |\n",
      "|    explained_variance   | 0.767      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0533    |\n",
      "|    n_updates            | 4150       |\n",
      "|    policy_gradient_loss | -0.0399    |\n",
      "|    value_loss           | 0.0174     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 1105        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058864236 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.389      |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0506     |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 0.041       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 1111        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050566237 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.445      |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0457     |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.0246      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 174        |\n",
      "|    time_elapsed         | 1116       |\n",
      "|    total_timesteps      | 356352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04971335 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.352     |\n",
      "|    explained_variance   | -0.789     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00645   |\n",
      "|    n_updates            | 4180       |\n",
      "|    policy_gradient_loss | -0.0256    |\n",
      "|    value_loss           | 0.00775    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 175        |\n",
      "|    time_elapsed         | 1122       |\n",
      "|    total_timesteps      | 358400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06691649 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.489     |\n",
      "|    explained_variance   | 0.833      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0757    |\n",
      "|    n_updates            | 4190       |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    value_loss           | 0.0227     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 176        |\n",
      "|    time_elapsed         | 1128       |\n",
      "|    total_timesteps      | 360448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08246906 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.602     |\n",
      "|    explained_variance   | 0.281      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0394    |\n",
      "|    n_updates            | 4200       |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.00985    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 177        |\n",
      "|    time_elapsed         | 1134       |\n",
      "|    total_timesteps      | 362496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10451583 |\n",
      "|    clip_fraction        | 0.361      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.497     |\n",
      "|    explained_variance   | 0.574      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0205    |\n",
      "|    n_updates            | 4210       |\n",
      "|    policy_gradient_loss | -0.0436    |\n",
      "|    value_loss           | 0.0333     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 178        |\n",
      "|    time_elapsed         | 1139       |\n",
      "|    total_timesteps      | 364544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08665537 |\n",
      "|    clip_fraction        | 0.412      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.476     |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0725    |\n",
      "|    n_updates            | 4220       |\n",
      "|    policy_gradient_loss | -0.0362    |\n",
      "|    value_loss           | 0.0236     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 320        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 1145       |\n",
      "|    total_timesteps      | 366592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07887439 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.464     |\n",
      "|    explained_variance   | 0.56       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0549    |\n",
      "|    n_updates            | 4230       |\n",
      "|    policy_gradient_loss | -0.0374    |\n",
      "|    value_loss           | 0.0282     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 320        |\n",
      "|    iterations           | 180        |\n",
      "|    time_elapsed         | 1150       |\n",
      "|    total_timesteps      | 368640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03810808 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.339     |\n",
      "|    explained_variance   | 0.417      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0544    |\n",
      "|    n_updates            | 4240       |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.00202    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 320       |\n",
      "|    iterations           | 181       |\n",
      "|    time_elapsed         | 1156      |\n",
      "|    total_timesteps      | 370688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0605578 |\n",
      "|    clip_fraction        | 0.205     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.415    |\n",
      "|    explained_variance   | 0.636     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0247   |\n",
      "|    n_updates            | 4250      |\n",
      "|    policy_gradient_loss | -0.0296   |\n",
      "|    value_loss           | 0.0303    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 1161        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052498825 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0467     |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.0248      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 1167        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028910656 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.256      |\n",
      "|    explained_variance   | -0.379      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0233     |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.00468     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 1172        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045098104 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.486      |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0472     |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.0234      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 321        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 1178       |\n",
      "|    total_timesteps      | 378880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08682561 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.533     |\n",
      "|    explained_variance   | 0.551      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0647    |\n",
      "|    n_updates            | 4290       |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.0213     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 1183        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056154646 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0481     |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 0.00717     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 1189        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057391748 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.448      |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00967    |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.0215      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 322        |\n",
      "|    iterations           | 188        |\n",
      "|    time_elapsed         | 1195       |\n",
      "|    total_timesteps      | 385024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11309541 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.399     |\n",
      "|    explained_variance   | 0.0529     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0449    |\n",
      "|    n_updates            | 4320       |\n",
      "|    policy_gradient_loss | -0.00776   |\n",
      "|    value_loss           | 0.00544    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 322        |\n",
      "|    iterations           | 189        |\n",
      "|    time_elapsed         | 1200       |\n",
      "|    total_timesteps      | 387072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05433132 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.416     |\n",
      "|    explained_variance   | 0.75       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0241    |\n",
      "|    n_updates            | 4330       |\n",
      "|    policy_gradient_loss | -0.0236    |\n",
      "|    value_loss           | 0.0255     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 1205        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051405903 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.402      |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0322     |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 0.00707     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 1211        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.069181085 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.44       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.0372      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 1216        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060702067 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 0.0734      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 1223        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050463922 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.538      |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.066      |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 0.0199      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 323        |\n",
      "|    iterations           | 194        |\n",
      "|    time_elapsed         | 1229       |\n",
      "|    total_timesteps      | 397312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06597487 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.576     |\n",
      "|    explained_variance   | 0.649      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00387   |\n",
      "|    n_updates            | 4380       |\n",
      "|    policy_gradient_loss | -0.0351    |\n",
      "|    value_loss           | 0.0313     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 1236        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043677717 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.459      |\n",
      "|    explained_variance   | -0.423      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0245     |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 322       |\n",
      "|    iterations           | 196       |\n",
      "|    time_elapsed         | 1243      |\n",
      "|    total_timesteps      | 401408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0398111 |\n",
      "|    clip_fraction        | 0.219     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.531    |\n",
      "|    explained_variance   | 0.764     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0384   |\n",
      "|    n_updates            | 4400      |\n",
      "|    policy_gradient_loss | -0.0256   |\n",
      "|    value_loss           | 0.0186    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 1249        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054681484 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.519      |\n",
      "|    explained_variance   | -1.26       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0703     |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 0.0214      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 1254        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050572246 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.559      |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0582     |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 1260        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082409784 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.179       |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.0731      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 323        |\n",
      "|    iterations           | 200        |\n",
      "|    time_elapsed         | 1266       |\n",
      "|    total_timesteps      | 409600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08359283 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.51      |\n",
      "|    explained_variance   | 0.574      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0452    |\n",
      "|    n_updates            | 4440       |\n",
      "|    policy_gradient_loss | -0.0347    |\n",
      "|    value_loss           | 0.0236     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 323        |\n",
      "|    iterations           | 201        |\n",
      "|    time_elapsed         | 1272       |\n",
      "|    total_timesteps      | 411648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04133153 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.762     |\n",
      "|    explained_variance   | -0.102     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0744    |\n",
      "|    n_updates            | 4450       |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.00526    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 1277        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043708533 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.038      |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.0183      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 1283        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036544126 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.452      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0523     |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 0.00515     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 323        |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 1289       |\n",
      "|    total_timesteps      | 417792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07904993 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.448     |\n",
      "|    explained_variance   | 0.43       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0323    |\n",
      "|    n_updates            | 4480       |\n",
      "|    policy_gradient_loss | -0.0359    |\n",
      "|    value_loss           | 0.0663     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 324        |\n",
      "|    iterations           | 205        |\n",
      "|    time_elapsed         | 1295       |\n",
      "|    total_timesteps      | 419840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03829605 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.766     |\n",
      "|    explained_variance   | 0.827      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.054     |\n",
      "|    n_updates            | 4490       |\n",
      "|    policy_gradient_loss | -0.0338    |\n",
      "|    value_loss           | 0.0121     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 324         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 1301        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042160522 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0114     |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    value_loss           | 0.0263      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 324        |\n",
      "|    iterations           | 207        |\n",
      "|    time_elapsed         | 1306       |\n",
      "|    total_timesteps      | 423936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06596525 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.366     |\n",
      "|    explained_variance   | 0.341      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0335    |\n",
      "|    n_updates            | 4510       |\n",
      "|    policy_gradient_loss | -0.0432    |\n",
      "|    value_loss           | 0.0657     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 324        |\n",
      "|    iterations           | 208        |\n",
      "|    time_elapsed         | 1312       |\n",
      "|    total_timesteps      | 425984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03869661 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.355     |\n",
      "|    explained_variance   | 0.753      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0545    |\n",
      "|    n_updates            | 4520       |\n",
      "|    policy_gradient_loss | -0.0244    |\n",
      "|    value_loss           | 0.0303     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 324        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 1318       |\n",
      "|    total_timesteps      | 428032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09168671 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.552     |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0496    |\n",
      "|    n_updates            | 4530       |\n",
      "|    policy_gradient_loss | -0.0289    |\n",
      "|    value_loss           | 0.0231     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 324         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 1323        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053424567 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.696      |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.079      |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.0512     |\n",
      "|    value_loss           | 0.0263      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 325        |\n",
      "|    iterations           | 211        |\n",
      "|    time_elapsed         | 1328       |\n",
      "|    total_timesteps      | 432128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06202512 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.767     |\n",
      "|    explained_variance   | 0.675      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00941   |\n",
      "|    n_updates            | 4550       |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    value_loss           | 0.0128     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 325        |\n",
      "|    iterations           | 212        |\n",
      "|    time_elapsed         | 1333       |\n",
      "|    total_timesteps      | 434176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07040379 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.521     |\n",
      "|    explained_variance   | 0.549      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0672    |\n",
      "|    n_updates            | 4560       |\n",
      "|    policy_gradient_loss | -0.0329    |\n",
      "|    value_loss           | 0.0286     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 1339        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035558637 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000243    |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 0.00823     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 1345        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.115591325 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.064      |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 0.0785      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 325        |\n",
      "|    iterations           | 215        |\n",
      "|    time_elapsed         | 1352       |\n",
      "|    total_timesteps      | 440320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04782532 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.513     |\n",
      "|    explained_variance   | 0.832      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.061     |\n",
      "|    n_updates            | 4590       |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 0.0246     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 325        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 1358       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12077686 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.384     |\n",
      "|    explained_variance   | -2.88      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.065     |\n",
      "|    n_updates            | 4600       |\n",
      "|    policy_gradient_loss | -0.0442    |\n",
      "|    value_loss           | 0.00537    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 325        |\n",
      "|    iterations           | 217        |\n",
      "|    time_elapsed         | 1364       |\n",
      "|    total_timesteps      | 444416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05049417 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.491     |\n",
      "|    explained_variance   | 0.498      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0295    |\n",
      "|    n_updates            | 4610       |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.0311     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 1370        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058324028 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.464      |\n",
      "|    explained_variance   | 0.0489      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0578     |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 0.0186      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 325        |\n",
      "|    iterations           | 219        |\n",
      "|    time_elapsed         | 1375       |\n",
      "|    total_timesteps      | 448512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42254254 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.349     |\n",
      "|    explained_variance   | 0.353      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0489    |\n",
      "|    n_updates            | 4630       |\n",
      "|    policy_gradient_loss | -0.0407    |\n",
      "|    value_loss           | 0.0282     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 326        |\n",
      "|    iterations           | 220        |\n",
      "|    time_elapsed         | 1380       |\n",
      "|    total_timesteps      | 450560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05205805 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.417     |\n",
      "|    explained_variance   | -0.185     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0284    |\n",
      "|    n_updates            | 4640       |\n",
      "|    policy_gradient_loss | -0.00963   |\n",
      "|    value_loss           | 0.0681     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 1386        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056583777 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.42       |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.045      |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 0.0351      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 1391        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037350208 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | -0.723      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00529    |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.0164      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 1396        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059568077 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0324     |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.0156      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 1402        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056973383 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.177      |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0304     |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.015       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 1407        |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045730956 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.409      |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 0.0222      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 327        |\n",
      "|    iterations           | 226        |\n",
      "|    time_elapsed         | 1413       |\n",
      "|    total_timesteps      | 462848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02645215 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.388     |\n",
      "|    explained_variance   | 0.815      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0348    |\n",
      "|    n_updates            | 4700       |\n",
      "|    policy_gradient_loss | -0.0228    |\n",
      "|    value_loss           | 0.012      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 327        |\n",
      "|    iterations           | 227        |\n",
      "|    time_elapsed         | 1419       |\n",
      "|    total_timesteps      | 464896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06624018 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.475     |\n",
      "|    explained_variance   | 0.508      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0312    |\n",
      "|    n_updates            | 4710       |\n",
      "|    policy_gradient_loss | -0.02      |\n",
      "|    value_loss           | 0.126      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 327        |\n",
      "|    iterations           | 228        |\n",
      "|    time_elapsed         | 1424       |\n",
      "|    total_timesteps      | 466944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04625901 |\n",
      "|    clip_fraction        | 0.28       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.508     |\n",
      "|    explained_variance   | 0.609      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0475    |\n",
      "|    n_updates            | 4720       |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 327        |\n",
      "|    iterations           | 229        |\n",
      "|    time_elapsed         | 1429       |\n",
      "|    total_timesteps      | 468992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06037084 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.415     |\n",
      "|    explained_variance   | 0.417      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0566    |\n",
      "|    n_updates            | 4730       |\n",
      "|    policy_gradient_loss | -0.0352    |\n",
      "|    value_loss           | 0.0245     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 328         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 1435        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042603187 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0527     |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 0.0178      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 328        |\n",
      "|    iterations           | 231        |\n",
      "|    time_elapsed         | 1440       |\n",
      "|    total_timesteps      | 473088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03860568 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.579     |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00497   |\n",
      "|    n_updates            | 4750       |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    value_loss           | 0.0129     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 328         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 1445        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.072794795 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.056      |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 0.0295      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 328         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 1450        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.098451585 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.405      |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0363     |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.0565      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 329        |\n",
      "|    iterations           | 234        |\n",
      "|    time_elapsed         | 1455       |\n",
      "|    total_timesteps      | 479232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03702482 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.764     |\n",
      "|    explained_variance   | 0.0665     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0225    |\n",
      "|    n_updates            | 4780       |\n",
      "|    policy_gradient_loss | -0.031     |\n",
      "|    value_loss           | 0.0196     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 329         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 1460        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038633697 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.588      |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0318     |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 0.0143      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 329         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 1465        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.092412025 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.456      |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0191     |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 0.00309     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 329        |\n",
      "|    iterations           | 237        |\n",
      "|    time_elapsed         | 1471       |\n",
      "|    total_timesteps      | 485376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04124338 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.443     |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0358    |\n",
      "|    n_updates            | 4810       |\n",
      "|    policy_gradient_loss | -0.0259    |\n",
      "|    value_loss           | 0.0192     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 330        |\n",
      "|    iterations           | 238        |\n",
      "|    time_elapsed         | 1476       |\n",
      "|    total_timesteps      | 487424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07550883 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.749     |\n",
      "|    explained_variance   | -0.724     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.071      |\n",
      "|    n_updates            | 4820       |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.00183    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 330         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 1482        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060271498 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.644      |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0122      |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.019       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 330        |\n",
      "|    iterations           | 240        |\n",
      "|    time_elapsed         | 1488       |\n",
      "|    total_timesteps      | 491520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06389525 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.586     |\n",
      "|    explained_variance   | 0.626      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0559    |\n",
      "|    n_updates            | 4840       |\n",
      "|    policy_gradient_loss | -0.0375    |\n",
      "|    value_loss           | 0.016      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 330        |\n",
      "|    iterations           | 241        |\n",
      "|    time_elapsed         | 1494       |\n",
      "|    total_timesteps      | 493568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05104451 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.559     |\n",
      "|    explained_variance   | 0.473      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0507    |\n",
      "|    n_updates            | 4850       |\n",
      "|    policy_gradient_loss | -0.024     |\n",
      "|    value_loss           | 0.0337     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 330        |\n",
      "|    iterations           | 242        |\n",
      "|    time_elapsed         | 1499       |\n",
      "|    total_timesteps      | 495616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07428564 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.403     |\n",
      "|    explained_variance   | 0.0919     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.072     |\n",
      "|    n_updates            | 4860       |\n",
      "|    policy_gradient_loss | -0.0456    |\n",
      "|    value_loss           | 0.017      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 330        |\n",
      "|    iterations           | 243        |\n",
      "|    time_elapsed         | 1504       |\n",
      "|    total_timesteps      | 497664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07841663 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.499     |\n",
      "|    explained_variance   | 0.606      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0675    |\n",
      "|    n_updates            | 4870       |\n",
      "|    policy_gradient_loss | -0.0259    |\n",
      "|    value_loss           | 0.0138     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 330       |\n",
      "|    iterations           | 244       |\n",
      "|    time_elapsed         | 1509      |\n",
      "|    total_timesteps      | 499712    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0738409 |\n",
      "|    clip_fraction        | 0.254     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.564    |\n",
      "|    explained_variance   | 0.723     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.031    |\n",
      "|    n_updates            | 4880      |\n",
      "|    policy_gradient_loss | -0.0347   |\n",
      "|    value_loss           | 0.00517   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 331        |\n",
      "|    iterations           | 245        |\n",
      "|    time_elapsed         | 1515       |\n",
      "|    total_timesteps      | 501760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06127485 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.526     |\n",
      "|    explained_variance   | 0.851      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0441    |\n",
      "|    n_updates            | 4890       |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.0127     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2da4eb48190>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PPO_DRL_model.learn(total_timesteps=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dd6b4",
   "metadata": {},
   "source": [
    "## Save PPO DRL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO_Model_Custom = os.path.join('Training_Star_Wars_Galaxy_Phase_3', 'Saved RL Models', 'PPO_Model_Star_Wars_Galaxy_1M')\n",
    "# PPO_DRL_model.save(PPO_Model_Custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce62ff80",
   "metadata": {},
   "source": [
    "## Reload PPO DRL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a67ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "PPO_Model_Custom = os.path.join('Training_Star_Wars_Galaxy_Phase_3', 'Saved RL Models', 'PPO_Model_Star_Wars_Galaxy_1M')\n",
    "reloaded_PPO_DRL_model = PPO.load(PPO_Model_Custom, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c305f3",
   "metadata": {},
   "source": [
    "## Test the PPO DRL model in a RL Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5562c2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inner Episode 1 ---\n",
      "Outer Episode: 1 | Inner Episode Score: 186.63 | Cumulative Score So Far: 186.63 | Planets Found so far: 1/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 18\n",
      "\n",
      "--- Inner Episode 2 ---\n",
      "Outer Episode: 1 | Inner Episode Score: 585.75 | Cumulative Score So Far: 772.38 | Planets Found so far: 6/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 3 ---\n",
      "Outer Episode: 1 | Inner Episode Score: 363.63 | Cumulative Score So Far: 1136.01 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 4 ---\n",
      "Outer Episode: 1 | Inner Episode Score: -35.28 | Cumulative Score So Far: 1100.73 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 66\n",
      "\n",
      "--- Inner Episode 5 ---\n",
      "Outer Episode: 1 | Inner Episode Score: 47.50 | Cumulative Score So Far: 1148.23 | Planets Found so far: 15/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 10\n",
      "\n",
      "--- Inner Episode 6 ---\n",
      "Outer Episode: 1 | Inner Episode Score: -76.61 | Cumulative Score So Far: 1071.62 | Planets Found so far: 17/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 7 ---\n",
      "Outer Episode: 1 | Inner Episode Score: -184.02 | Cumulative Score So Far: 887.60 | Planets Found so far: 17/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 8 ---\n",
      "Outer Episode: 1 | Inner Episode Score: -184.17 | Cumulative Score So Far: 703.43 | Planets Found so far: 17/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 9 ---\n",
      "Outer Episode: 1 | Inner Episode Score: -181.93 | Cumulative Score So Far: 521.50 | Planets Found so far: 17/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 10 ---\n",
      "Outer Episode: 1 | Inner Episode Score: -184.04 | Cumulative Score So Far: 337.45 | Planets Found so far: 17/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 11 ---\n",
      "Outer Episode: 1 | Inner Episode Score: -185.44 | Cumulative Score So Far: 152.01 | Planets Found so far: 17/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 12 ---\n",
      "Outer Episode: 1 | Inner Episode Score: -43.28 | Cumulative Score So Far: 108.74 | Planets Found so far: 17/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 23\n",
      "\n",
      "--- Inner Episode 13 ---\n",
      "Outer Episode: 1 | Inner Episode Score: -185.64 | Cumulative Score So Far: -76.90 | Planets Found so far: 17/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 14 ---\n",
      "Outer Episode: 1 | Inner Episode Score: -344.38 | Cumulative Score So Far: -421.29 | Planets Found so far: 18/18 | Damages to Inner Episode Drone: 5 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 15 (Final) ---\n",
      "Outer Episode: 1 | Inner Episode Score: -200.53 | Cumulative Score So Far: -621.82 | Planets Found so far: 18/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "=== End of Outer Episode 1 | Total Return: -621.82 ===\n",
      "\n",
      "--- Inner Episode 1 ---\n",
      "Outer Episode: 2 | Inner Episode Score: 210.53 | Cumulative Score So Far: 210.53 | Planets Found so far: 1/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 19\n",
      "\n",
      "--- Inner Episode 2 ---\n",
      "Outer Episode: 2 | Inner Episode Score: 206.14 | Cumulative Score So Far: 416.67 | Planets Found so far: 3/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 47\n",
      "\n",
      "--- Inner Episode 3 ---\n",
      "Outer Episode: 2 | Inner Episode Score: 426.44 | Cumulative Score So Far: 843.10 | Planets Found so far: 10/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 4 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -2614.97 | Cumulative Score So Far: -1771.87 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 92 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 5 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -33.46 | Cumulative Score So Far: -1805.33 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 25\n",
      "\n",
      "--- Inner Episode 6 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -50.91 | Cumulative Score So Far: -1856.24 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 17\n",
      "\n",
      "--- Inner Episode 7 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -107.65 | Cumulative Score So Far: -1963.89 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 91\n",
      "\n",
      "--- Inner Episode 8 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -188.82 | Cumulative Score So Far: -2152.71 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 9 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -177.47 | Cumulative Score So Far: -2330.19 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 10 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -67.82 | Cumulative Score So Far: -2398.01 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 2 | Steps Survived: 14\n",
      "\n",
      "--- Inner Episode 11 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -179.22 | Cumulative Score So Far: -2577.23 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 12 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -14.70 | Cumulative Score So Far: -2591.93 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 23\n",
      "\n",
      "--- Inner Episode 13 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -161.91 | Cumulative Score So Far: -2753.85 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 14 ---\n",
      "Outer Episode: 2 | Inner Episode Score: -172.43 | Cumulative Score So Far: -2926.28 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 15 (Final) ---\n",
      "Outer Episode: 2 | Inner Episode Score: -23.35 | Cumulative Score So Far: -2949.63 | Planets Found so far: 14/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 14\n",
      "\n",
      "=== End of Outer Episode 2 | Total Return: -2949.63 ===\n",
      "\n",
      "--- Inner Episode 1 ---\n",
      "Outer Episode: 3 | Inner Episode Score: 498.65 | Cumulative Score So Far: 498.65 | Planets Found so far: 4/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 142\n",
      "\n",
      "--- Inner Episode 2 ---\n",
      "Outer Episode: 3 | Inner Episode Score: 279.65 | Cumulative Score So Far: 778.30 | Planets Found so far: 6/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 40\n",
      "\n",
      "--- Inner Episode 3 ---\n",
      "Outer Episode: 3 | Inner Episode Score: 97.90 | Cumulative Score So Far: 876.20 | Planets Found so far: 8/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 69\n",
      "\n",
      "--- Inner Episode 4 ---\n",
      "Outer Episode: 3 | Inner Episode Score: 54.26 | Cumulative Score So Far: 930.46 | Planets Found so far: 10/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 84\n",
      "\n",
      "--- Inner Episode 5 ---\n",
      "Outer Episode: 3 | Inner Episode Score: 63.85 | Cumulative Score So Far: 994.31 | Planets Found so far: 13/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 6 ---\n",
      "Outer Episode: 3 | Inner Episode Score: 14.82 | Cumulative Score So Far: 1009.13 | Planets Found so far: 15/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 167\n",
      "\n",
      "--- Inner Episode 7 ---\n",
      "Outer Episode: 3 | Inner Episode Score: -185.59 | Cumulative Score So Far: 823.54 | Planets Found so far: 15/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 8 ---\n",
      "Outer Episode: 3 | Inner Episode Score: -188.53 | Cumulative Score So Far: 635.00 | Planets Found so far: 15/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 9 ---\n",
      "Outer Episode: 3 | Inner Episode Score: -192.01 | Cumulative Score So Far: 442.99 | Planets Found so far: 15/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n",
      "\n",
      "--- Inner Episode 10 ---\n",
      "Outer Episode: 3 | Inner Episode Score: -145.93 | Cumulative Score So Far: 297.06 | Planets Found so far: 16/18 | Damages to Inner Episode Drone: 0 | Steps Survived: 300\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env = OuterRimEnvWithMetaEpisodes(n_sep=2, n_rep=2, sub_limit=15)\n",
    "\n",
    "episodes = 3\n",
    "for episode in range(1, episodes+1):\n",
    "    # Initialise starting state of the RL agent in the RL Environment before an episode, done to false, and starting \n",
    "    # episode score to 0\n",
    "    obs, _ = env.reset()    # → hard_reset (new galaxy)\n",
    "    # print(f\"Initial State: {obs}\")\n",
    "    done = False\n",
    "    outer_episode_score = 0.0\n",
    "\n",
    "    inner_episode = 1\n",
    "    inner_episode_score = 0.0\n",
    "    inner_episode_steps = 0\n",
    "    inner_episode_damages = 0\n",
    "\n",
    "    # During an episode:\n",
    "    while not done:\n",
    "        env.render()\n",
    "        # RL agent determines action to take\n",
    "        # - Now, we are no longer randomly sampling an action to take by our RL agent in the RL Environment, but\n",
    "        #   instead we are using the PPO DRL model to predict the action at each time step in an episode instead based\n",
    "        #   on the current observations/states in the RL Environment\n",
    "        action, _ = reloaded_PPO_DRL_model.predict(obs)\n",
    "        # RL Environment generates the next state and reward gained upon taking the action in the current state\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        # Append the reward gained upon taking the action in the current state to the cumulative episode date\n",
    "        inner_episode_score += reward\n",
    "        outer_episode_score += reward\n",
    "        inner_episode_steps += 1\n",
    "\n",
    "        ###########################################\n",
    "        # Detect the moment a soft-reset happened #\n",
    "        ###########################################\n",
    "        if info.get(\"soft_reset\", False):\n",
    "            print(f\"\\n--- Inner Episode {inner_episode} ---\")\n",
    "            print(f\"Outer Episode: {episode} | Inner Episode Score: {inner_episode_score:.2f} | \"\n",
    "                  f\"Cumulative Score So Far: {outer_episode_score:.2f} | \"\n",
    "                  f\"Planets Found so far: {info['visited_planets']}/{info['total_planets']} | \"\n",
    "                  f\"Damages to Inner Episode Drone: {info['damages'] - inner_episode_damages} | \"\n",
    "                  f\"Steps Survived: {inner_episode_steps}\")\n",
    "            \n",
    "            inner_episode += 1\n",
    "            inner_episode_score = 0.0\n",
    "            inner_episode_steps = 0\n",
    "            inner_episode_damages = info['damages']\n",
    "\n",
    "    print(f\"\\n--- Inner Episode {inner_episode} (Final) ---\")\n",
    "    print(f\"Outer Episode: {episode} | Inner Episode Score: {inner_episode_score:.2f} | \"\n",
    "          f\"Cumulative Score So Far: {outer_episode_score:.2f} | \"\n",
    "          f\"Planets Found so far: {info['visited_planets']}/{info['total_planets']} | \"\n",
    "          f\"Damages to Inner Episode Drone: {info['damages'] - inner_episode_damages} | \"\n",
    "          f\"Steps Survived: {inner_episode_steps}\")\n",
    "    \n",
    "    print(f\"\\n=== End of Outer Episode {episode} | Total Return: {outer_episode_score:.2f} ===\")\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
